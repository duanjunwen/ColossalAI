<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <style>
    html, body {
      margin: 0;
      padding: 0;
      background-color: #f7f6f6;
      font-family: "Roboto", sans-serif;
      color: #333333;
    }
    .separator {
            height: 2px;
            background-image: linear-gradient(to right, #999, #ddd, #999);
            background-size: 100% 1px;
            background-repeat: no-repeat;
            background-position: center;
            margin: 20px 0;
        }

    body {
      display: flex;
      justify-content: center;
      align-items: center;
      margin: 0;
      padding-bottom: 15px;
    }

    .content {
      min-height: calc(100vh - 60px);
      width: 80%;
    }

    .collapsible-header {
      cursor: pointer;
      font-family: "Roboto", Arial, sans-serif;
      background-color: #dbd9d9;
      padding: 15px;
      border-radius: 4px;
      box-shadow: 2px 4px 4px rgba(0, 0, 0, 0.2);
    }
    .collapsible-header:hover {
      background-color: #dddbdb;
      transform: scale(1.02);
    }

    .collapsible-content {
      display: none;
      padding: 12px;
    }
    .collapsible-header.opened {
      background-color: #333333;
      color: #dbd9d9;
    }
    div{margin:5px;
        border:0;
        padding:0;}
    h2 {
      margin:10px;
      border:0;
      padding:0;}
    h1 {
      text-align: center;
      color: #333;
      margin-top: 10px;
      font-family: "Roboto", Arial, sans-serif;
      font-size: 25px;
      letter-spacing: 2px;
      padding-bottom: 20px;
      border-bottom: 1px solid #ddd;
    }

    table {
      width: 100%;
      table-layout: fixed;
      border-collapse: collapse;
      margin-top: 2px;
      margin-bottom: 5px;
    }

    th, td {
      padding: 10px;
      word-wrap: break-word;
      word-break: break-all;
      white-space: normal;
      border: 1px solid rgb(170, 169, 169);
      text-align: left;
    }

    th {
      background-color: #d1d0d0;
      color: #000000;
      font-weight: bold;
      text-align: center;
    }

    tr:nth-child(even) {
      background-color: #e7e7e7;
    }

    tr:hover {
      background-color: #acaaaa;
    }
    .footer {
      text-align: center;
      position: fixed;
      bottom: 0;
      margin: 0;
      letter-spacing: 1px;
      left: 0;
      width: 100%;
      padding: 2px 0;
      color: #777;
      height: 35px;
      background-color: #f7f6f6;
      border-top: 1px solid #ddd;
      opacity: 1;
    }
    #timeline_api_stack {
      font-size: 15px;
      color: #004a8f;
    }
    #timeline_api_instruction {
      padding-left:5px;
    }
    .non-stack-api-box {
      cursor: pointer;
      font-family: "Roboto", Arial, sans-serif;
      background-color: #dbd9d9;
      padding: 15px;
      border-radius: 4px;
      box-shadow: 2px 4px 4px rgba(0, 0, 0, 0.2);
    }
  </style>
</head>
<body>

<div class="content">
<h1><b>Performance Optimization Suggestions</b></h1>

<div style="display: flex; align-items: center;">
  <span style="color: black; font-weight: bold">Optimization Priority: </span>
  <div style="width: 20px; height: 20px; background-color: #B5495B; margin-right: 10px;"></div>
  <span style="color: #B5495B;">High</span>
  <div style="width: 20px; height: 20px; background-color: #fcaf17; margin: 0 10px;"></div>
  <span style="color: #fcaf17;">Medium</span>
  <div style="width: 20px; height: 20px; background-color: #65c294; margin-right: 10px;"></div>
  <span style="color: #65c294;">Low</span>
</div>


    
    <div class="collapsible">
        <h2 class="collapsible-header">overall</h2>
        <div class="collapsible-content">
            
            <div class="collapsible">
    <h2 class="collapsible-header">Environment Variable Issues</h2>
    <div class="collapsible-content">
        <table>
            <tr>
                
                <th>Environment</th>
                
                <th>Value</th>
                
                <th>Description</th>
                
                <th>Suggestion</th>
                
            </tr>
            <tr>
                
                <tr>
                    
                    <td>ACLNN_CACHE_LIMIT</td>
                    
                    <td></td>
                    
                    <td>缓存的aclnn算子的数量。</td>
                    
                    <td>在alcnn和host耗时过长时，可以设置一个较大的数字，例如'export ACLNN_CACHE_LIMIT=100000'。</td>
                    
                </tr>
                
                <tr>
                    
                    <td>HOST_CACHE_CAPACITY</td>
                    
                    <td></td>
                    
                    <td>启用动态shape缓存。<br> 默认值为0，表示数据缓存已禁用。<br> 如果设置为非零正整数，例如10，系统将缓存最近频繁出现的10个输入形状的执行数据。<br> 当缓存的形状再次出现时，host执行性能将得到提高，但host内存使用量会增加。<br> 具体的增加与HOST_CACHE_CAPACITY的值和模型的大小成正比。</td>
                    
                    <td>设置一个非零数字，例如'export HOST_CACHE_CAPACITY=20'</td>
                    
                </tr>
                
                <tr>
                    
                    <td>ASCEND_ENHANCE_ENABLE</td>
                    
                    <td></td>
                    
                    <td>启用hccl ffts+模式。0-禁用，1-启用。</td>
                    
                    <td>建议通过执行命令'export ASCEND_ENHANCE_enable=1'启用hccl ffts+模式。</td>
                    
                </tr>
                
                <tr>
                    
                    <td>PYTORCH_NPU_ALLOC_CONF</td>
                    
                    <td></td>
                    
                    <td>控制缓存分配器的行为。<br> 可选参数为max_split_size_mb、garbage_collection_threshold和expandable_segments。<br> 1.max_split_size_mb：v —— 大于v的内存块不会被分割。<br> 2.garbage_collection_threshold：t —— 设置阈值后，如果NPU内存使用量超过阈值，缓存分配器将开始回收内存块。t的取值范围为（0.0，1.0）。<br> 3.expandable_segments:True/False —— 默认值为False。如果为True，则此设置指示缓存分配器创建特定的内存块，这些内存块可以在以后扩展，以更好地处理频繁更改的内存使用情况。</td>
                    
                    <td>export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True</td>
                    
                </tr>
                
                <tr>
                    
                    <td>ASCEND_LAUNCH_BLOCKING</td>
                    
                    <td></td>
                    
                    <td>是否在操作执行期间启用同步模式。<br> 当设置为1时，强制算子同步运行，从而更容易调试和跟踪代码中的问题。<br> 如果设置为0，则任务将以异步模式执行。</td>
                    
                    <td>export ASCEND_LAUNCH_BLOCKING=1</td>
                    
                </tr>
                
            </tr>
        </table>
    </div>
</div>
            
            <div class="collapsible">
    <h2 class="collapsible-header">slow rank</h2>
    <div class="collapsible-content">
        <div class="collapsible">

            
            <div class="collapsible-header">Description</div>
            <div class="collapsible-content">
                <a>集群中的通信有问题， 
因为通信时间的最大差距已经达到 
103060.644ms。 
集群中的空闲有问题， 
因为空闲时间的最大差距已经达到 
99304.586ms。 
</a>
            </div>
            

            

            
            <div class="collapsible-header">details</div>
            <div class="collapsible-content">
                
                <table>
                    <tr>
                        
                        <td>step</td>
                        
                        <td>rank_id</td>
                        
                        <td>compute(us)</td>
                        
                        <td>communication(us)</td>
                        
                        <td>free(us)</td>
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>1556714.06</td>
                        
                        
                        
                        <td>87232581.34</td>
                        
                        
                        
                        <td>36829097.07</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>1</td>
                        
                        
                        
                        <td>1560276.45</td>
                        
                        
                        
                        <td>78997510.16</td>
                        
                        
                        
                        <td>43698754.88</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>2</td>
                        
                        
                        
                        <td>1558312.8</td>
                        
                        
                        
                        <td>40868325.82</td>
                        
                        
                        
                        <td>79587869.88</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>3</td>
                        
                        
                        
                        <td>1556942.22</td>
                        
                        
                        
                        <td>98397199.24</td>
                        
                        
                        
                        <td>25134636.69</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>4</td>
                        
                        
                        
                        <td>1761254.86</td>
                        
                        
                        
                        <td>45969395.1</td>
                        
                        
                        
                        <td>77693774.04</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>5</td>
                        
                        
                        
                        <td>1765175.92</td>
                        
                        
                        
                        <td>56016250.64</td>
                        
                        
                        
                        <td>65924566.11</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>6</td>
                        
                        
                        
                        <td>1762990.27</td>
                        
                        
                        
                        <td>3041651.13</td>
                        
                        
                        
                        <td>117837748.23</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>7</td>
                        
                        
                        
                        <td>1763501.67</td>
                        
                        
                        
                        <td>52671041.62</td>
                        
                        
                        
                        <td>69509934.54</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>8</td>
                        
                        
                        
                        <td>1561748.03</td>
                        
                        
                        
                        <td>44449697.11</td>
                        
                        
                        
                        <td>76268659.57</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>9</td>
                        
                        
                        
                        <td>1557930.15</td>
                        
                        
                        
                        <td>103663859.49</td>
                        
                        
                        
                        <td>20203496.84</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>10</td>
                        
                        
                        
                        <td>1558704.98</td>
                        
                        
                        
                        <td>87122155.7</td>
                        
                        
                        
                        <td>35402682.33</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>11</td>
                        
                        
                        
                        <td>1557350.52</td>
                        
                        
                        
                        <td>105052622.01</td>
                        
                        
                        
                        <td>18533162.23</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>12</td>
                        
                        
                        
                        <td>1763293.74</td>
                        
                        
                        
                        <td>66816420.23</td>
                        
                        
                        
                        <td>48098511.97</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>13</td>
                        
                        
                        
                        <td>1760975.6</td>
                        
                        
                        
                        <td>1991978.28</td>
                        
                        
                        
                        <td>111975738.82</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>14</td>
                        
                        
                        
                        <td>1759204.7</td>
                        
                        
                        
                        <td>44457564.92</td>
                        
                        
                        
                        <td>68792652.51</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>15</td>
                        
                        
                        
                        <td>1762214.47</td>
                        
                        
                        
                        <td>58791678.64</td>
                        
                        
                        
                        <td>56870330.29</td>
                        
                        
                    </tr>
                    
                </table>
                
            </div>
            

        </div>

    </div>
</div>
            
            <div class="collapsible">
    <h2 class="collapsible-header">slow link</h2>
    <div class="collapsible-content">
        <div class="collapsible">

            
            <div class="collapsible-header">Description</div>
            <div class="collapsible-content">
                <a>RDMA bandwidth(GB/s)： 
    平均值是 23.997， 
    但最大值是 24.017GB/s ，
    最小值是 23.983GB/s。
    差距为 0.034GB/s。 
SDMA bandwidth(GB/s)： 
    平均值是 17.935， 
    但最大值是 18.663GB/s ，
    最小值是 17.174GB/s。
    差距为 1.49GB/s。 
</a>
            </div>
            

            

            
            <div class="collapsible-header">details</div>
            <div class="collapsible-content">
                
                <table>
                    <tr>
                        
                        <td>step</td>
                        
                        <td>rank_id</td>
                        
                        <td>RDMA bandwidth(GB/s)</td>
                        
                        <td>RDMA size(mb)</td>
                        
                        <td>RDMA time(ms)</td>
                        
                        <td>SDMA bandwidth(GB/s)</td>
                        
                        <td>SDMA size(mb)</td>
                        
                        <td>SDMA time(ms)</td>
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>23.99</td>
                        
                        
                        
                        <td>7616.22</td>
                        
                        
                        
                        <td>317.46</td>
                        
                        
                        
                        <td>18.41</td>
                        
                        
                        
                        <td>70229.43</td>
                        
                        
                        
                        <td>3813.77</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>1</td>
                        
                        
                        
                        <td>24.02</td>
                        
                        
                        
                        <td>7616.22</td>
                        
                        
                        
                        <td>317.12</td>
                        
                        
                        
                        <td>17.52</td>
                        
                        
                        
                        <td>70230.23</td>
                        
                        
                        
                        <td>4008.1</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>2</td>
                        
                        
                        
                        <td>23.98</td>
                        
                        
                        
                        <td>7616.22</td>
                        
                        
                        
                        <td>317.55</td>
                        
                        
                        
                        <td>18.59</td>
                        
                        
                        
                        <td>70230.23</td>
                        
                        
                        
                        <td>3777.48</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>3</td>
                        
                        
                        
                        <td>24.01</td>
                        
                        
                        
                        <td>7616.22</td>
                        
                        
                        
                        <td>317.21</td>
                        
                        
                        
                        <td>18.66</td>
                        
                        
                        
                        <td>70230.23</td>
                        
                        
                        
                        <td>3763.05</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>4</td>
                        
                        
                        
                        <td>24.0</td>
                        
                        
                        
                        <td>7616.24</td>
                        
                        
                        
                        <td>317.37</td>
                        
                        
                        
                        <td>17.17</td>
                        
                        
                        
                        <td>70229.43</td>
                        
                        
                        
                        <td>4089.41</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>5</td>
                        
                        
                        
                        <td>24.01</td>
                        
                        
                        
                        <td>7616.24</td>
                        
                        
                        
                        <td>317.24</td>
                        
                        
                        
                        <td>17.2</td>
                        
                        
                        
                        <td>70231.31</td>
                        
                        
                        
                        <td>4083.65</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>6</td>
                        
                        
                        
                        <td>24.0</td>
                        
                        
                        
                        <td>7616.24</td>
                        
                        
                        
                        <td>317.29</td>
                        
                        
                        
                        <td>17.38</td>
                        
                        
                        
                        <td>70231.31</td>
                        
                        
                        
                        <td>4041.88</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>7</td>
                        
                        
                        
                        <td>24.01</td>
                        
                        
                        
                        <td>7616.24</td>
                        
                        
                        
                        <td>317.22</td>
                        
                        
                        
                        <td>18.43</td>
                        
                        
                        
                        <td>70231.31</td>
                        
                        
                        
                        <td>3811.14</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>8</td>
                        
                        
                        
                        <td>23.99</td>
                        
                        
                        
                        <td>7616.22</td>
                        
                        
                        
                        <td>317.48</td>
                        
                        
                        
                        <td>18.39</td>
                        
                        
                        
                        <td>70229.43</td>
                        
                        
                        
                        <td>3819.49</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>9</td>
                        
                        
                        
                        <td>24.0</td>
                        
                        
                        
                        <td>7616.22</td>
                        
                        
                        
                        <td>317.35</td>
                        
                        
                        
                        <td>17.6</td>
                        
                        
                        
                        <td>70230.23</td>
                        
                        
                        
                        <td>3990.1</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>10</td>
                        
                        
                        
                        <td>23.99</td>
                        
                        
                        
                        <td>7616.22</td>
                        
                        
                        
                        <td>317.45</td>
                        
                        
                        
                        <td>18.64</td>
                        
                        
                        
                        <td>70230.23</td>
                        
                        
                        
                        <td>3768.14</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>11</td>
                        
                        
                        
                        <td>23.99</td>
                        
                        
                        
                        <td>7616.22</td>
                        
                        
                        
                        <td>317.44</td>
                        
                        
                        
                        <td>18.57</td>
                        
                        
                        
                        <td>70230.23</td>
                        
                        
                        
                        <td>3782.16</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>12</td>
                        
                        
                        
                        <td>24.0</td>
                        
                        
                        
                        <td>7616.24</td>
                        
                        
                        
                        <td>317.34</td>
                        
                        
                        
                        <td>17.24</td>
                        
                        
                        
                        <td>70229.43</td>
                        
                        
                        
                        <td>4074.61</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>13</td>
                        
                        
                        
                        <td>23.98</td>
                        
                        
                        
                        <td>7616.24</td>
                        
                        
                        
                        <td>317.57</td>
                        
                        
                        
                        <td>17.41</td>
                        
                        
                        
                        <td>70231.31</td>
                        
                        
                        
                        <td>4035.02</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>14</td>
                        
                        
                        
                        <td>23.98</td>
                        
                        
                        
                        <td>7616.24</td>
                        
                        
                        
                        <td>317.56</td>
                        
                        
                        
                        <td>17.24</td>
                        
                        
                        
                        <td>70231.31</td>
                        
                        
                        
                        <td>4074.82</td>
                        
                        
                    </tr>
                    
                    <tr>
                        
                        
                        <td>0</td>
                        
                        
                        
                        <td>15</td>
                        
                        
                        
                        <td>23.99</td>
                        
                        
                        
                        <td>7616.24</td>
                        
                        
                        
                        <td>317.5</td>
                        
                        
                        
                        <td>18.52</td>
                        
                        
                        
                        <td>70231.31</td>
                        
                        
                        
                        <td>3792.47</td>
                        
                        
                    </tr>
                    
                </table>
                
            </div>
            

        </div>

    </div>
</div>
            
        </div>
    </div>
    

    
    <div class="collapsible">
        <h2 class="collapsible-header">comparison</h2>
        <div class="collapsible-content">
            
            
<div class="collapsible">
      <h2 class="collapsible-header" style="background-color: ;">Kernel compare of Rank4 Step0 and Rank0 Step0</h2>
      <div class="collapsible-content">
            <a style="font-weight: bold" id="timeline_api_instruction_issue">Issue: Kernel compare of Rank4 Step0 and Rank0 Step0. Only show 10 rows here, see mstt_advisor*.xlsx for details</a>
            <br><br>
            <table>
                <tr>
                
                    <th> Order Id </th>
                
                    <th> Kernel Type </th>
                
                    <th> Core Type </th>
                
                    <th> Total Duration(us) </th>
                
                    <th> Avg Duration(us) </th>
                
                    <th> Max Duration(us) </th>
                
                    <th> Min Duration(us) </th>
                
                    <th> Calls </th>
                
                    <th> Benchmark  Total Duration(us) </th>
                
                    <th> Benchmark  Avg Duration(us) </th>
                
                    <th> Benchmark  Max Duration(us) </th>
                
                    <th> Benchmark  Min Duration(us) </th>
                
                    <th> Benchmark  Calls </th>
                
                    <th> Diff Total Ratio </th>
                
                    <th> Diff Avg Ratio </th>
                
                </tr>

                
                <tr>
                    
                    <td>1</td>
                    
                    <td>GatherV2</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>1316.306</td>
                    
                    <td>658.153</td>
                    
                    <td>660.833</td>
                    
                    <td>655.473</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>2</td>
                    
                    <td>EmbeddingDenseGradV2</td>
                    
                    <td>MIX_AIV</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>899.178</td>
                    
                    <td>449.589</td>
                    
                    <td>451.049</td>
                    
                    <td>448.129</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>3</td>
                    
                    <td>MemSet</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>122.302</td>
                    
                    <td>10.192</td>
                    
                    <td>12.68</td>
                    
                    <td>6.56</td>
                    
                    <td>12</td>
                    
                    <td>761.135</td>
                    
                    <td>63.428</td>
                    
                    <td>337.366</td>
                    
                    <td>5.46</td>
                    
                    <td>12</td>
                    
                    <td>6.2234</td>
                    
                    <td>6.2233</td>
                    
                </tr>
                
                <tr>
                    
                    <td>39</td>
                    
                    <td>Range</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>49.381</td>
                    
                    <td>12.345</td>
                    
                    <td>12.661</td>
                    
                    <td>11.921</td>
                    
                    <td>4</td>
                    
                    <td>29.181</td>
                    
                    <td>14.591</td>
                    
                    <td>14.64</td>
                    
                    <td>14.54</td>
                    
                    <td>2</td>
                    
                    <td>0.5909</td>
                    
                    <td>1.1819</td>
                    
                </tr>
                
                <tr>
                    
                    <td>4</td>
                    
                    <td>GreaterEqual</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>16.901</td>
                    
                    <td>8.45</td>
                    
                    <td>8.56</td>
                    
                    <td>8.341</td>
                    
                    <td>2</td>
                    
                    <td>19.081</td>
                    
                    <td>9.54</td>
                    
                    <td>9.681</td>
                    
                    <td>9.4</td>
                    
                    <td>2</td>
                    
                    <td>1.129</td>
                    
                    <td>1.129</td>
                    
                </tr>
                
                <tr>
                    
                    <td>43</td>
                    
                    <td>Fill</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>15.881</td>
                    
                    <td>1.444</td>
                    
                    <td>1.6</td>
                    
                    <td>1.3</td>
                    
                    <td>11</td>
                    
                    <td>6.52</td>
                    
                    <td>1.63</td>
                    
                    <td>1.88</td>
                    
                    <td>1.42</td>
                    
                    <td>4</td>
                    
                    <td>0.4106</td>
                    
                    <td>1.1288</td>
                    
                </tr>
                
                <tr>
                    
                    <td>38</td>
                    
                    <td>LinearIndexV2</td>
                    
                    <td>MIX_AIV</td>
                    
                    <td>121.502</td>
                    
                    <td>20.25</td>
                    
                    <td>20.86</td>
                    
                    <td>18.881</td>
                    
                    <td>6</td>
                    
                    <td>90.682</td>
                    
                    <td>22.671</td>
                    
                    <td>24.34</td>
                    
                    <td>21.541</td>
                    
                    <td>4</td>
                    
                    <td>0.7463</td>
                    
                    <td>1.1196</td>
                    
                </tr>
                
                <tr>
                    
                    <td>5</td>
                    
                    <td>Less</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>21.441</td>
                    
                    <td>10.72</td>
                    
                    <td>11.28</td>
                    
                    <td>10.161</td>
                    
                    <td>2</td>
                    
                    <td>23.921</td>
                    
                    <td>11.96</td>
                    
                    <td>12.581</td>
                    
                    <td>11.34</td>
                    
                    <td>2</td>
                    
                    <td>1.1157</td>
                    
                    <td>1.1157</td>
                    
                </tr>
                
                <tr>
                    
                    <td>6</td>
                    
                    <td>Addcmul</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>11961.336</td>
                    
                    <td>35.18</td>
                    
                    <td>889.337</td>
                    
                    <td>2.0</td>
                    
                    <td>340</td>
                    
                    <td>12491.693</td>
                    
                    <td>36.958</td>
                    
                    <td>895.998</td>
                    
                    <td>2.04</td>
                    
                    <td>338</td>
                    
                    <td>1.0443</td>
                    
                    <td>1.0505</td>
                    
                </tr>
                
                <tr>
                    
                    <td>7</td>
                    
                    <td>Addcdiv</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>13155.317</td>
                    
                    <td>38.692</td>
                    
                    <td>1144.902</td>
                    
                    <td>1.94</td>
                    
                    <td>340</td>
                    
                    <td>13414.21</td>
                    
                    <td>39.687</td>
                    
                    <td>1141.842</td>
                    
                    <td>1.98</td>
                    
                    <td>338</td>
                    
                    <td>1.0197</td>
                    
                    <td>1.0257</td>
                    
                </tr>
                
            </table>

        </div>
</div>

            
            
<div class="collapsible">
      <h2 class="collapsible-header" style="background-color: ;">Kernel compare of Rank5 Step0 and Rank1 Step0</h2>
      <div class="collapsible-content">
            <a style="font-weight: bold" id="timeline_api_instruction_issue">Issue: Kernel compare of Rank5 Step0 and Rank1 Step0. Only show 10 rows here, see mstt_advisor*.xlsx for details</a>
            <br><br>
            <table>
                <tr>
                
                    <th> Order Id </th>
                
                    <th> Kernel Type </th>
                
                    <th> Core Type </th>
                
                    <th> Total Duration(us) </th>
                
                    <th> Avg Duration(us) </th>
                
                    <th> Max Duration(us) </th>
                
                    <th> Min Duration(us) </th>
                
                    <th> Calls </th>
                
                    <th> Benchmark  Total Duration(us) </th>
                
                    <th> Benchmark  Avg Duration(us) </th>
                
                    <th> Benchmark  Max Duration(us) </th>
                
                    <th> Benchmark  Min Duration(us) </th>
                
                    <th> Benchmark  Calls </th>
                
                    <th> Diff Total Ratio </th>
                
                    <th> Diff Avg Ratio </th>
                
                </tr>

                
                <tr>
                    
                    <td>1</td>
                    
                    <td>GatherV2</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>1316.306</td>
                    
                    <td>658.153</td>
                    
                    <td>660.833</td>
                    
                    <td>655.473</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>2</td>
                    
                    <td>EmbeddingDenseGradV2</td>
                    
                    <td>MIX_AIV</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>899.178</td>
                    
                    <td>449.589</td>
                    
                    <td>451.049</td>
                    
                    <td>448.129</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>3</td>
                    
                    <td>MemSet</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>122.302</td>
                    
                    <td>10.192</td>
                    
                    <td>12.68</td>
                    
                    <td>6.56</td>
                    
                    <td>12</td>
                    
                    <td>761.135</td>
                    
                    <td>63.428</td>
                    
                    <td>337.366</td>
                    
                    <td>5.46</td>
                    
                    <td>12</td>
                    
                    <td>6.2234</td>
                    
                    <td>6.2233</td>
                    
                </tr>
                
                <tr>
                    
                    <td>39</td>
                    
                    <td>Range</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>49.381</td>
                    
                    <td>12.345</td>
                    
                    <td>12.661</td>
                    
                    <td>11.921</td>
                    
                    <td>4</td>
                    
                    <td>29.181</td>
                    
                    <td>14.591</td>
                    
                    <td>14.64</td>
                    
                    <td>14.54</td>
                    
                    <td>2</td>
                    
                    <td>0.5909</td>
                    
                    <td>1.1819</td>
                    
                </tr>
                
                <tr>
                    
                    <td>4</td>
                    
                    <td>GreaterEqual</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>16.901</td>
                    
                    <td>8.45</td>
                    
                    <td>8.56</td>
                    
                    <td>8.341</td>
                    
                    <td>2</td>
                    
                    <td>19.081</td>
                    
                    <td>9.54</td>
                    
                    <td>9.681</td>
                    
                    <td>9.4</td>
                    
                    <td>2</td>
                    
                    <td>1.129</td>
                    
                    <td>1.129</td>
                    
                </tr>
                
                <tr>
                    
                    <td>43</td>
                    
                    <td>Fill</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>15.881</td>
                    
                    <td>1.444</td>
                    
                    <td>1.6</td>
                    
                    <td>1.3</td>
                    
                    <td>11</td>
                    
                    <td>6.52</td>
                    
                    <td>1.63</td>
                    
                    <td>1.88</td>
                    
                    <td>1.42</td>
                    
                    <td>4</td>
                    
                    <td>0.4106</td>
                    
                    <td>1.1288</td>
                    
                </tr>
                
                <tr>
                    
                    <td>38</td>
                    
                    <td>LinearIndexV2</td>
                    
                    <td>MIX_AIV</td>
                    
                    <td>121.502</td>
                    
                    <td>20.25</td>
                    
                    <td>20.86</td>
                    
                    <td>18.881</td>
                    
                    <td>6</td>
                    
                    <td>90.682</td>
                    
                    <td>22.671</td>
                    
                    <td>24.34</td>
                    
                    <td>21.541</td>
                    
                    <td>4</td>
                    
                    <td>0.7463</td>
                    
                    <td>1.1196</td>
                    
                </tr>
                
                <tr>
                    
                    <td>5</td>
                    
                    <td>Less</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>21.441</td>
                    
                    <td>10.72</td>
                    
                    <td>11.28</td>
                    
                    <td>10.161</td>
                    
                    <td>2</td>
                    
                    <td>23.921</td>
                    
                    <td>11.96</td>
                    
                    <td>12.581</td>
                    
                    <td>11.34</td>
                    
                    <td>2</td>
                    
                    <td>1.1157</td>
                    
                    <td>1.1157</td>
                    
                </tr>
                
                <tr>
                    
                    <td>6</td>
                    
                    <td>Addcmul</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>11961.336</td>
                    
                    <td>35.18</td>
                    
                    <td>889.337</td>
                    
                    <td>2.0</td>
                    
                    <td>340</td>
                    
                    <td>12491.693</td>
                    
                    <td>36.958</td>
                    
                    <td>895.998</td>
                    
                    <td>2.04</td>
                    
                    <td>338</td>
                    
                    <td>1.0443</td>
                    
                    <td>1.0505</td>
                    
                </tr>
                
                <tr>
                    
                    <td>7</td>
                    
                    <td>Addcdiv</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>13155.317</td>
                    
                    <td>38.692</td>
                    
                    <td>1144.902</td>
                    
                    <td>1.94</td>
                    
                    <td>340</td>
                    
                    <td>13414.21</td>
                    
                    <td>39.687</td>
                    
                    <td>1141.842</td>
                    
                    <td>1.98</td>
                    
                    <td>338</td>
                    
                    <td>1.0197</td>
                    
                    <td>1.0257</td>
                    
                </tr>
                
            </table>

        </div>
</div>

            
            
<div class="collapsible">
      <h2 class="collapsible-header" style="background-color: ;">Kernel compare of Rank6 Step0 and Rank2 Step0</h2>
      <div class="collapsible-content">
            <a style="font-weight: bold" id="timeline_api_instruction_issue">Issue: Kernel compare of Rank6 Step0 and Rank2 Step0. Only show 10 rows here, see mstt_advisor*.xlsx for details</a>
            <br><br>
            <table>
                <tr>
                
                    <th> Order Id </th>
                
                    <th> Kernel Type </th>
                
                    <th> Core Type </th>
                
                    <th> Total Duration(us) </th>
                
                    <th> Avg Duration(us) </th>
                
                    <th> Max Duration(us) </th>
                
                    <th> Min Duration(us) </th>
                
                    <th> Calls </th>
                
                    <th> Benchmark  Total Duration(us) </th>
                
                    <th> Benchmark  Avg Duration(us) </th>
                
                    <th> Benchmark  Max Duration(us) </th>
                
                    <th> Benchmark  Min Duration(us) </th>
                
                    <th> Benchmark  Calls </th>
                
                    <th> Diff Total Ratio </th>
                
                    <th> Diff Avg Ratio </th>
                
                </tr>

                
                <tr>
                    
                    <td>1</td>
                    
                    <td>GatherV2</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>1316.306</td>
                    
                    <td>658.153</td>
                    
                    <td>660.833</td>
                    
                    <td>655.473</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>2</td>
                    
                    <td>EmbeddingDenseGradV2</td>
                    
                    <td>MIX_AIV</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>899.178</td>
                    
                    <td>449.589</td>
                    
                    <td>451.049</td>
                    
                    <td>448.129</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>3</td>
                    
                    <td>MemSet</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>122.302</td>
                    
                    <td>10.192</td>
                    
                    <td>12.68</td>
                    
                    <td>6.56</td>
                    
                    <td>12</td>
                    
                    <td>761.135</td>
                    
                    <td>63.428</td>
                    
                    <td>337.366</td>
                    
                    <td>5.46</td>
                    
                    <td>12</td>
                    
                    <td>6.2234</td>
                    
                    <td>6.2233</td>
                    
                </tr>
                
                <tr>
                    
                    <td>39</td>
                    
                    <td>Range</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>49.381</td>
                    
                    <td>12.345</td>
                    
                    <td>12.661</td>
                    
                    <td>11.921</td>
                    
                    <td>4</td>
                    
                    <td>29.181</td>
                    
                    <td>14.591</td>
                    
                    <td>14.64</td>
                    
                    <td>14.54</td>
                    
                    <td>2</td>
                    
                    <td>0.5909</td>
                    
                    <td>1.1819</td>
                    
                </tr>
                
                <tr>
                    
                    <td>4</td>
                    
                    <td>GreaterEqual</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>16.901</td>
                    
                    <td>8.45</td>
                    
                    <td>8.56</td>
                    
                    <td>8.341</td>
                    
                    <td>2</td>
                    
                    <td>19.081</td>
                    
                    <td>9.54</td>
                    
                    <td>9.681</td>
                    
                    <td>9.4</td>
                    
                    <td>2</td>
                    
                    <td>1.129</td>
                    
                    <td>1.129</td>
                    
                </tr>
                
                <tr>
                    
                    <td>43</td>
                    
                    <td>Fill</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>15.881</td>
                    
                    <td>1.444</td>
                    
                    <td>1.6</td>
                    
                    <td>1.3</td>
                    
                    <td>11</td>
                    
                    <td>6.52</td>
                    
                    <td>1.63</td>
                    
                    <td>1.88</td>
                    
                    <td>1.42</td>
                    
                    <td>4</td>
                    
                    <td>0.4106</td>
                    
                    <td>1.1288</td>
                    
                </tr>
                
                <tr>
                    
                    <td>38</td>
                    
                    <td>LinearIndexV2</td>
                    
                    <td>MIX_AIV</td>
                    
                    <td>121.502</td>
                    
                    <td>20.25</td>
                    
                    <td>20.86</td>
                    
                    <td>18.881</td>
                    
                    <td>6</td>
                    
                    <td>90.682</td>
                    
                    <td>22.671</td>
                    
                    <td>24.34</td>
                    
                    <td>21.541</td>
                    
                    <td>4</td>
                    
                    <td>0.7463</td>
                    
                    <td>1.1196</td>
                    
                </tr>
                
                <tr>
                    
                    <td>5</td>
                    
                    <td>Less</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>21.441</td>
                    
                    <td>10.72</td>
                    
                    <td>11.28</td>
                    
                    <td>10.161</td>
                    
                    <td>2</td>
                    
                    <td>23.921</td>
                    
                    <td>11.96</td>
                    
                    <td>12.581</td>
                    
                    <td>11.34</td>
                    
                    <td>2</td>
                    
                    <td>1.1157</td>
                    
                    <td>1.1157</td>
                    
                </tr>
                
                <tr>
                    
                    <td>6</td>
                    
                    <td>Addcmul</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>11961.336</td>
                    
                    <td>35.18</td>
                    
                    <td>889.337</td>
                    
                    <td>2.0</td>
                    
                    <td>340</td>
                    
                    <td>12491.693</td>
                    
                    <td>36.958</td>
                    
                    <td>895.998</td>
                    
                    <td>2.04</td>
                    
                    <td>338</td>
                    
                    <td>1.0443</td>
                    
                    <td>1.0505</td>
                    
                </tr>
                
                <tr>
                    
                    <td>7</td>
                    
                    <td>Addcdiv</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>13155.317</td>
                    
                    <td>38.692</td>
                    
                    <td>1144.902</td>
                    
                    <td>1.94</td>
                    
                    <td>340</td>
                    
                    <td>13414.21</td>
                    
                    <td>39.687</td>
                    
                    <td>1141.842</td>
                    
                    <td>1.98</td>
                    
                    <td>338</td>
                    
                    <td>1.0197</td>
                    
                    <td>1.0257</td>
                    
                </tr>
                
            </table>

        </div>
</div>

            
            
<div class="collapsible">
      <h2 class="collapsible-header" style="background-color: ;">Kernel compare of Rank7 Step0 and Rank3 Step0</h2>
      <div class="collapsible-content">
            <a style="font-weight: bold" id="timeline_api_instruction_issue">Issue: Kernel compare of Rank7 Step0 and Rank3 Step0. Only show 10 rows here, see mstt_advisor*.xlsx for details</a>
            <br><br>
            <table>
                <tr>
                
                    <th> Order Id </th>
                
                    <th> Kernel Type </th>
                
                    <th> Core Type </th>
                
                    <th> Total Duration(us) </th>
                
                    <th> Avg Duration(us) </th>
                
                    <th> Max Duration(us) </th>
                
                    <th> Min Duration(us) </th>
                
                    <th> Calls </th>
                
                    <th> Benchmark  Total Duration(us) </th>
                
                    <th> Benchmark  Avg Duration(us) </th>
                
                    <th> Benchmark  Max Duration(us) </th>
                
                    <th> Benchmark  Min Duration(us) </th>
                
                    <th> Benchmark  Calls </th>
                
                    <th> Diff Total Ratio </th>
                
                    <th> Diff Avg Ratio </th>
                
                </tr>

                
                <tr>
                    
                    <td>1</td>
                    
                    <td>GatherV2</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>1316.306</td>
                    
                    <td>658.153</td>
                    
                    <td>660.833</td>
                    
                    <td>655.473</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>2</td>
                    
                    <td>EmbeddingDenseGradV2</td>
                    
                    <td>MIX_AIV</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>899.178</td>
                    
                    <td>449.589</td>
                    
                    <td>451.049</td>
                    
                    <td>448.129</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>3</td>
                    
                    <td>MemSet</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>122.302</td>
                    
                    <td>10.192</td>
                    
                    <td>12.68</td>
                    
                    <td>6.56</td>
                    
                    <td>12</td>
                    
                    <td>761.135</td>
                    
                    <td>63.428</td>
                    
                    <td>337.366</td>
                    
                    <td>5.46</td>
                    
                    <td>12</td>
                    
                    <td>6.2234</td>
                    
                    <td>6.2233</td>
                    
                </tr>
                
                <tr>
                    
                    <td>39</td>
                    
                    <td>Range</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>49.381</td>
                    
                    <td>12.345</td>
                    
                    <td>12.661</td>
                    
                    <td>11.921</td>
                    
                    <td>4</td>
                    
                    <td>29.181</td>
                    
                    <td>14.591</td>
                    
                    <td>14.64</td>
                    
                    <td>14.54</td>
                    
                    <td>2</td>
                    
                    <td>0.5909</td>
                    
                    <td>1.1819</td>
                    
                </tr>
                
                <tr>
                    
                    <td>4</td>
                    
                    <td>GreaterEqual</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>16.901</td>
                    
                    <td>8.45</td>
                    
                    <td>8.56</td>
                    
                    <td>8.341</td>
                    
                    <td>2</td>
                    
                    <td>19.081</td>
                    
                    <td>9.54</td>
                    
                    <td>9.681</td>
                    
                    <td>9.4</td>
                    
                    <td>2</td>
                    
                    <td>1.129</td>
                    
                    <td>1.129</td>
                    
                </tr>
                
                <tr>
                    
                    <td>43</td>
                    
                    <td>Fill</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>15.881</td>
                    
                    <td>1.444</td>
                    
                    <td>1.6</td>
                    
                    <td>1.3</td>
                    
                    <td>11</td>
                    
                    <td>6.52</td>
                    
                    <td>1.63</td>
                    
                    <td>1.88</td>
                    
                    <td>1.42</td>
                    
                    <td>4</td>
                    
                    <td>0.4106</td>
                    
                    <td>1.1288</td>
                    
                </tr>
                
                <tr>
                    
                    <td>38</td>
                    
                    <td>LinearIndexV2</td>
                    
                    <td>MIX_AIV</td>
                    
                    <td>121.502</td>
                    
                    <td>20.25</td>
                    
                    <td>20.86</td>
                    
                    <td>18.881</td>
                    
                    <td>6</td>
                    
                    <td>90.682</td>
                    
                    <td>22.671</td>
                    
                    <td>24.34</td>
                    
                    <td>21.541</td>
                    
                    <td>4</td>
                    
                    <td>0.7463</td>
                    
                    <td>1.1196</td>
                    
                </tr>
                
                <tr>
                    
                    <td>5</td>
                    
                    <td>Less</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>21.441</td>
                    
                    <td>10.72</td>
                    
                    <td>11.28</td>
                    
                    <td>10.161</td>
                    
                    <td>2</td>
                    
                    <td>23.921</td>
                    
                    <td>11.96</td>
                    
                    <td>12.581</td>
                    
                    <td>11.34</td>
                    
                    <td>2</td>
                    
                    <td>1.1157</td>
                    
                    <td>1.1157</td>
                    
                </tr>
                
                <tr>
                    
                    <td>6</td>
                    
                    <td>Addcmul</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>11961.336</td>
                    
                    <td>35.18</td>
                    
                    <td>889.337</td>
                    
                    <td>2.0</td>
                    
                    <td>340</td>
                    
                    <td>12491.693</td>
                    
                    <td>36.958</td>
                    
                    <td>895.998</td>
                    
                    <td>2.04</td>
                    
                    <td>338</td>
                    
                    <td>1.0443</td>
                    
                    <td>1.0505</td>
                    
                </tr>
                
                <tr>
                    
                    <td>7</td>
                    
                    <td>Addcdiv</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>13155.317</td>
                    
                    <td>38.692</td>
                    
                    <td>1144.902</td>
                    
                    <td>1.94</td>
                    
                    <td>340</td>
                    
                    <td>13414.21</td>
                    
                    <td>39.687</td>
                    
                    <td>1141.842</td>
                    
                    <td>1.98</td>
                    
                    <td>338</td>
                    
                    <td>1.0197</td>
                    
                    <td>1.0257</td>
                    
                </tr>
                
            </table>

        </div>
</div>

            
            
<div class="collapsible">
      <h2 class="collapsible-header" style="background-color: ;">Kernel compare of Rank12 Step0 and Rank8 Step0</h2>
      <div class="collapsible-content">
            <a style="font-weight: bold" id="timeline_api_instruction_issue">Issue: Kernel compare of Rank12 Step0 and Rank8 Step0. Only show 10 rows here, see mstt_advisor*.xlsx for details</a>
            <br><br>
            <table>
                <tr>
                
                    <th> Order Id </th>
                
                    <th> Kernel Type </th>
                
                    <th> Core Type </th>
                
                    <th> Total Duration(us) </th>
                
                    <th> Avg Duration(us) </th>
                
                    <th> Max Duration(us) </th>
                
                    <th> Min Duration(us) </th>
                
                    <th> Calls </th>
                
                    <th> Benchmark  Total Duration(us) </th>
                
                    <th> Benchmark  Avg Duration(us) </th>
                
                    <th> Benchmark  Max Duration(us) </th>
                
                    <th> Benchmark  Min Duration(us) </th>
                
                    <th> Benchmark  Calls </th>
                
                    <th> Diff Total Ratio </th>
                
                    <th> Diff Avg Ratio </th>
                
                </tr>

                
                <tr>
                    
                    <td>1</td>
                    
                    <td>GatherV2</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>1316.306</td>
                    
                    <td>658.153</td>
                    
                    <td>660.833</td>
                    
                    <td>655.473</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>2</td>
                    
                    <td>EmbeddingDenseGradV2</td>
                    
                    <td>MIX_AIV</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>899.178</td>
                    
                    <td>449.589</td>
                    
                    <td>451.049</td>
                    
                    <td>448.129</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>3</td>
                    
                    <td>MemSet</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>122.302</td>
                    
                    <td>10.192</td>
                    
                    <td>12.68</td>
                    
                    <td>6.56</td>
                    
                    <td>12</td>
                    
                    <td>761.135</td>
                    
                    <td>63.428</td>
                    
                    <td>337.366</td>
                    
                    <td>5.46</td>
                    
                    <td>12</td>
                    
                    <td>6.2234</td>
                    
                    <td>6.2233</td>
                    
                </tr>
                
                <tr>
                    
                    <td>39</td>
                    
                    <td>Range</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>49.381</td>
                    
                    <td>12.345</td>
                    
                    <td>12.661</td>
                    
                    <td>11.921</td>
                    
                    <td>4</td>
                    
                    <td>29.181</td>
                    
                    <td>14.591</td>
                    
                    <td>14.64</td>
                    
                    <td>14.54</td>
                    
                    <td>2</td>
                    
                    <td>0.5909</td>
                    
                    <td>1.1819</td>
                    
                </tr>
                
                <tr>
                    
                    <td>4</td>
                    
                    <td>GreaterEqual</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>16.901</td>
                    
                    <td>8.45</td>
                    
                    <td>8.56</td>
                    
                    <td>8.341</td>
                    
                    <td>2</td>
                    
                    <td>19.081</td>
                    
                    <td>9.54</td>
                    
                    <td>9.681</td>
                    
                    <td>9.4</td>
                    
                    <td>2</td>
                    
                    <td>1.129</td>
                    
                    <td>1.129</td>
                    
                </tr>
                
                <tr>
                    
                    <td>43</td>
                    
                    <td>Fill</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>15.881</td>
                    
                    <td>1.444</td>
                    
                    <td>1.6</td>
                    
                    <td>1.3</td>
                    
                    <td>11</td>
                    
                    <td>6.52</td>
                    
                    <td>1.63</td>
                    
                    <td>1.88</td>
                    
                    <td>1.42</td>
                    
                    <td>4</td>
                    
                    <td>0.4106</td>
                    
                    <td>1.1288</td>
                    
                </tr>
                
                <tr>
                    
                    <td>38</td>
                    
                    <td>LinearIndexV2</td>
                    
                    <td>MIX_AIV</td>
                    
                    <td>121.502</td>
                    
                    <td>20.25</td>
                    
                    <td>20.86</td>
                    
                    <td>18.881</td>
                    
                    <td>6</td>
                    
                    <td>90.682</td>
                    
                    <td>22.671</td>
                    
                    <td>24.34</td>
                    
                    <td>21.541</td>
                    
                    <td>4</td>
                    
                    <td>0.7463</td>
                    
                    <td>1.1196</td>
                    
                </tr>
                
                <tr>
                    
                    <td>5</td>
                    
                    <td>Less</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>21.441</td>
                    
                    <td>10.72</td>
                    
                    <td>11.28</td>
                    
                    <td>10.161</td>
                    
                    <td>2</td>
                    
                    <td>23.921</td>
                    
                    <td>11.96</td>
                    
                    <td>12.581</td>
                    
                    <td>11.34</td>
                    
                    <td>2</td>
                    
                    <td>1.1157</td>
                    
                    <td>1.1157</td>
                    
                </tr>
                
                <tr>
                    
                    <td>6</td>
                    
                    <td>Addcmul</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>11961.336</td>
                    
                    <td>35.18</td>
                    
                    <td>889.337</td>
                    
                    <td>2.0</td>
                    
                    <td>340</td>
                    
                    <td>12491.693</td>
                    
                    <td>36.958</td>
                    
                    <td>895.998</td>
                    
                    <td>2.04</td>
                    
                    <td>338</td>
                    
                    <td>1.0443</td>
                    
                    <td>1.0505</td>
                    
                </tr>
                
                <tr>
                    
                    <td>7</td>
                    
                    <td>Addcdiv</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>13155.317</td>
                    
                    <td>38.692</td>
                    
                    <td>1144.902</td>
                    
                    <td>1.94</td>
                    
                    <td>340</td>
                    
                    <td>13414.21</td>
                    
                    <td>39.687</td>
                    
                    <td>1141.842</td>
                    
                    <td>1.98</td>
                    
                    <td>338</td>
                    
                    <td>1.0197</td>
                    
                    <td>1.0257</td>
                    
                </tr>
                
            </table>

        </div>
</div>

            
            
<div class="collapsible">
      <h2 class="collapsible-header" style="background-color: ;">Kernel compare of Rank13 Step0 and Rank9 Step0</h2>
      <div class="collapsible-content">
            <a style="font-weight: bold" id="timeline_api_instruction_issue">Issue: Kernel compare of Rank13 Step0 and Rank9 Step0. Only show 10 rows here, see mstt_advisor*.xlsx for details</a>
            <br><br>
            <table>
                <tr>
                
                    <th> Order Id </th>
                
                    <th> Kernel Type </th>
                
                    <th> Core Type </th>
                
                    <th> Total Duration(us) </th>
                
                    <th> Avg Duration(us) </th>
                
                    <th> Max Duration(us) </th>
                
                    <th> Min Duration(us) </th>
                
                    <th> Calls </th>
                
                    <th> Benchmark  Total Duration(us) </th>
                
                    <th> Benchmark  Avg Duration(us) </th>
                
                    <th> Benchmark  Max Duration(us) </th>
                
                    <th> Benchmark  Min Duration(us) </th>
                
                    <th> Benchmark  Calls </th>
                
                    <th> Diff Total Ratio </th>
                
                    <th> Diff Avg Ratio </th>
                
                </tr>

                
                <tr>
                    
                    <td>1</td>
                    
                    <td>GatherV2</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>1316.306</td>
                    
                    <td>658.153</td>
                    
                    <td>660.833</td>
                    
                    <td>655.473</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>2</td>
                    
                    <td>EmbeddingDenseGradV2</td>
                    
                    <td>MIX_AIV</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>899.178</td>
                    
                    <td>449.589</td>
                    
                    <td>451.049</td>
                    
                    <td>448.129</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>3</td>
                    
                    <td>MemSet</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>122.302</td>
                    
                    <td>10.192</td>
                    
                    <td>12.68</td>
                    
                    <td>6.56</td>
                    
                    <td>12</td>
                    
                    <td>761.135</td>
                    
                    <td>63.428</td>
                    
                    <td>337.366</td>
                    
                    <td>5.46</td>
                    
                    <td>12</td>
                    
                    <td>6.2234</td>
                    
                    <td>6.2233</td>
                    
                </tr>
                
                <tr>
                    
                    <td>39</td>
                    
                    <td>Range</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>49.381</td>
                    
                    <td>12.345</td>
                    
                    <td>12.661</td>
                    
                    <td>11.921</td>
                    
                    <td>4</td>
                    
                    <td>29.181</td>
                    
                    <td>14.591</td>
                    
                    <td>14.64</td>
                    
                    <td>14.54</td>
                    
                    <td>2</td>
                    
                    <td>0.5909</td>
                    
                    <td>1.1819</td>
                    
                </tr>
                
                <tr>
                    
                    <td>4</td>
                    
                    <td>GreaterEqual</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>16.901</td>
                    
                    <td>8.45</td>
                    
                    <td>8.56</td>
                    
                    <td>8.341</td>
                    
                    <td>2</td>
                    
                    <td>19.081</td>
                    
                    <td>9.54</td>
                    
                    <td>9.681</td>
                    
                    <td>9.4</td>
                    
                    <td>2</td>
                    
                    <td>1.129</td>
                    
                    <td>1.129</td>
                    
                </tr>
                
                <tr>
                    
                    <td>43</td>
                    
                    <td>Fill</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>15.881</td>
                    
                    <td>1.444</td>
                    
                    <td>1.6</td>
                    
                    <td>1.3</td>
                    
                    <td>11</td>
                    
                    <td>6.52</td>
                    
                    <td>1.63</td>
                    
                    <td>1.88</td>
                    
                    <td>1.42</td>
                    
                    <td>4</td>
                    
                    <td>0.4106</td>
                    
                    <td>1.1288</td>
                    
                </tr>
                
                <tr>
                    
                    <td>38</td>
                    
                    <td>LinearIndexV2</td>
                    
                    <td>MIX_AIV</td>
                    
                    <td>121.502</td>
                    
                    <td>20.25</td>
                    
                    <td>20.86</td>
                    
                    <td>18.881</td>
                    
                    <td>6</td>
                    
                    <td>90.682</td>
                    
                    <td>22.671</td>
                    
                    <td>24.34</td>
                    
                    <td>21.541</td>
                    
                    <td>4</td>
                    
                    <td>0.7463</td>
                    
                    <td>1.1196</td>
                    
                </tr>
                
                <tr>
                    
                    <td>5</td>
                    
                    <td>Less</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>21.441</td>
                    
                    <td>10.72</td>
                    
                    <td>11.28</td>
                    
                    <td>10.161</td>
                    
                    <td>2</td>
                    
                    <td>23.921</td>
                    
                    <td>11.96</td>
                    
                    <td>12.581</td>
                    
                    <td>11.34</td>
                    
                    <td>2</td>
                    
                    <td>1.1157</td>
                    
                    <td>1.1157</td>
                    
                </tr>
                
                <tr>
                    
                    <td>6</td>
                    
                    <td>Addcmul</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>11961.336</td>
                    
                    <td>35.18</td>
                    
                    <td>889.337</td>
                    
                    <td>2.0</td>
                    
                    <td>340</td>
                    
                    <td>12491.693</td>
                    
                    <td>36.958</td>
                    
                    <td>895.998</td>
                    
                    <td>2.04</td>
                    
                    <td>338</td>
                    
                    <td>1.0443</td>
                    
                    <td>1.0505</td>
                    
                </tr>
                
                <tr>
                    
                    <td>7</td>
                    
                    <td>Addcdiv</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>13155.317</td>
                    
                    <td>38.692</td>
                    
                    <td>1144.902</td>
                    
                    <td>1.94</td>
                    
                    <td>340</td>
                    
                    <td>13414.21</td>
                    
                    <td>39.687</td>
                    
                    <td>1141.842</td>
                    
                    <td>1.98</td>
                    
                    <td>338</td>
                    
                    <td>1.0197</td>
                    
                    <td>1.0257</td>
                    
                </tr>
                
            </table>

        </div>
</div>

            
            
<div class="collapsible">
      <h2 class="collapsible-header" style="background-color: ;">Kernel compare of Rank14 Step0 and Rank10 Step0</h2>
      <div class="collapsible-content">
            <a style="font-weight: bold" id="timeline_api_instruction_issue">Issue: Kernel compare of Rank14 Step0 and Rank10 Step0. Only show 10 rows here, see mstt_advisor*.xlsx for details</a>
            <br><br>
            <table>
                <tr>
                
                    <th> Order Id </th>
                
                    <th> Kernel Type </th>
                
                    <th> Core Type </th>
                
                    <th> Total Duration(us) </th>
                
                    <th> Avg Duration(us) </th>
                
                    <th> Max Duration(us) </th>
                
                    <th> Min Duration(us) </th>
                
                    <th> Calls </th>
                
                    <th> Benchmark  Total Duration(us) </th>
                
                    <th> Benchmark  Avg Duration(us) </th>
                
                    <th> Benchmark  Max Duration(us) </th>
                
                    <th> Benchmark  Min Duration(us) </th>
                
                    <th> Benchmark  Calls </th>
                
                    <th> Diff Total Ratio </th>
                
                    <th> Diff Avg Ratio </th>
                
                </tr>

                
                <tr>
                    
                    <td>1</td>
                    
                    <td>GatherV2</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>1316.306</td>
                    
                    <td>658.153</td>
                    
                    <td>660.833</td>
                    
                    <td>655.473</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>2</td>
                    
                    <td>EmbeddingDenseGradV2</td>
                    
                    <td>MIX_AIV</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>899.178</td>
                    
                    <td>449.589</td>
                    
                    <td>451.049</td>
                    
                    <td>448.129</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>3</td>
                    
                    <td>MemSet</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>122.302</td>
                    
                    <td>10.192</td>
                    
                    <td>12.68</td>
                    
                    <td>6.56</td>
                    
                    <td>12</td>
                    
                    <td>761.135</td>
                    
                    <td>63.428</td>
                    
                    <td>337.366</td>
                    
                    <td>5.46</td>
                    
                    <td>12</td>
                    
                    <td>6.2234</td>
                    
                    <td>6.2233</td>
                    
                </tr>
                
                <tr>
                    
                    <td>39</td>
                    
                    <td>Range</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>49.381</td>
                    
                    <td>12.345</td>
                    
                    <td>12.661</td>
                    
                    <td>11.921</td>
                    
                    <td>4</td>
                    
                    <td>29.181</td>
                    
                    <td>14.591</td>
                    
                    <td>14.64</td>
                    
                    <td>14.54</td>
                    
                    <td>2</td>
                    
                    <td>0.5909</td>
                    
                    <td>1.1819</td>
                    
                </tr>
                
                <tr>
                    
                    <td>4</td>
                    
                    <td>GreaterEqual</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>16.901</td>
                    
                    <td>8.45</td>
                    
                    <td>8.56</td>
                    
                    <td>8.341</td>
                    
                    <td>2</td>
                    
                    <td>19.081</td>
                    
                    <td>9.54</td>
                    
                    <td>9.681</td>
                    
                    <td>9.4</td>
                    
                    <td>2</td>
                    
                    <td>1.129</td>
                    
                    <td>1.129</td>
                    
                </tr>
                
                <tr>
                    
                    <td>43</td>
                    
                    <td>Fill</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>15.881</td>
                    
                    <td>1.444</td>
                    
                    <td>1.6</td>
                    
                    <td>1.3</td>
                    
                    <td>11</td>
                    
                    <td>6.52</td>
                    
                    <td>1.63</td>
                    
                    <td>1.88</td>
                    
                    <td>1.42</td>
                    
                    <td>4</td>
                    
                    <td>0.4106</td>
                    
                    <td>1.1288</td>
                    
                </tr>
                
                <tr>
                    
                    <td>38</td>
                    
                    <td>LinearIndexV2</td>
                    
                    <td>MIX_AIV</td>
                    
                    <td>121.502</td>
                    
                    <td>20.25</td>
                    
                    <td>20.86</td>
                    
                    <td>18.881</td>
                    
                    <td>6</td>
                    
                    <td>90.682</td>
                    
                    <td>22.671</td>
                    
                    <td>24.34</td>
                    
                    <td>21.541</td>
                    
                    <td>4</td>
                    
                    <td>0.7463</td>
                    
                    <td>1.1196</td>
                    
                </tr>
                
                <tr>
                    
                    <td>5</td>
                    
                    <td>Less</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>21.441</td>
                    
                    <td>10.72</td>
                    
                    <td>11.28</td>
                    
                    <td>10.161</td>
                    
                    <td>2</td>
                    
                    <td>23.921</td>
                    
                    <td>11.96</td>
                    
                    <td>12.581</td>
                    
                    <td>11.34</td>
                    
                    <td>2</td>
                    
                    <td>1.1157</td>
                    
                    <td>1.1157</td>
                    
                </tr>
                
                <tr>
                    
                    <td>6</td>
                    
                    <td>Addcmul</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>11961.336</td>
                    
                    <td>35.18</td>
                    
                    <td>889.337</td>
                    
                    <td>2.0</td>
                    
                    <td>340</td>
                    
                    <td>12491.693</td>
                    
                    <td>36.958</td>
                    
                    <td>895.998</td>
                    
                    <td>2.04</td>
                    
                    <td>338</td>
                    
                    <td>1.0443</td>
                    
                    <td>1.0505</td>
                    
                </tr>
                
                <tr>
                    
                    <td>7</td>
                    
                    <td>Addcdiv</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>13155.317</td>
                    
                    <td>38.692</td>
                    
                    <td>1144.902</td>
                    
                    <td>1.94</td>
                    
                    <td>340</td>
                    
                    <td>13414.21</td>
                    
                    <td>39.687</td>
                    
                    <td>1141.842</td>
                    
                    <td>1.98</td>
                    
                    <td>338</td>
                    
                    <td>1.0197</td>
                    
                    <td>1.0257</td>
                    
                </tr>
                
            </table>

        </div>
</div>

            
            
<div class="collapsible">
      <h2 class="collapsible-header" style="background-color: ;">Kernel compare of Rank15 Step0 and Rank11 Step0</h2>
      <div class="collapsible-content">
            <a style="font-weight: bold" id="timeline_api_instruction_issue">Issue: Kernel compare of Rank15 Step0 and Rank11 Step0. Only show 10 rows here, see mstt_advisor*.xlsx for details</a>
            <br><br>
            <table>
                <tr>
                
                    <th> Order Id </th>
                
                    <th> Kernel Type </th>
                
                    <th> Core Type </th>
                
                    <th> Total Duration(us) </th>
                
                    <th> Avg Duration(us) </th>
                
                    <th> Max Duration(us) </th>
                
                    <th> Min Duration(us) </th>
                
                    <th> Calls </th>
                
                    <th> Benchmark  Total Duration(us) </th>
                
                    <th> Benchmark  Avg Duration(us) </th>
                
                    <th> Benchmark  Max Duration(us) </th>
                
                    <th> Benchmark  Min Duration(us) </th>
                
                    <th> Benchmark  Calls </th>
                
                    <th> Diff Total Ratio </th>
                
                    <th> Diff Avg Ratio </th>
                
                </tr>

                
                <tr>
                    
                    <td>1</td>
                    
                    <td>GatherV2</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>1316.306</td>
                    
                    <td>658.153</td>
                    
                    <td>660.833</td>
                    
                    <td>655.473</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>2</td>
                    
                    <td>EmbeddingDenseGradV2</td>
                    
                    <td>MIX_AIV</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>899.178</td>
                    
                    <td>449.589</td>
                    
                    <td>451.049</td>
                    
                    <td>448.129</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>3</td>
                    
                    <td>MemSet</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>122.302</td>
                    
                    <td>10.192</td>
                    
                    <td>12.68</td>
                    
                    <td>6.56</td>
                    
                    <td>12</td>
                    
                    <td>761.135</td>
                    
                    <td>63.428</td>
                    
                    <td>337.366</td>
                    
                    <td>5.46</td>
                    
                    <td>12</td>
                    
                    <td>6.2234</td>
                    
                    <td>6.2233</td>
                    
                </tr>
                
                <tr>
                    
                    <td>39</td>
                    
                    <td>Range</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>49.381</td>
                    
                    <td>12.345</td>
                    
                    <td>12.661</td>
                    
                    <td>11.921</td>
                    
                    <td>4</td>
                    
                    <td>29.181</td>
                    
                    <td>14.591</td>
                    
                    <td>14.64</td>
                    
                    <td>14.54</td>
                    
                    <td>2</td>
                    
                    <td>0.5909</td>
                    
                    <td>1.1819</td>
                    
                </tr>
                
                <tr>
                    
                    <td>4</td>
                    
                    <td>GreaterEqual</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>16.901</td>
                    
                    <td>8.45</td>
                    
                    <td>8.56</td>
                    
                    <td>8.341</td>
                    
                    <td>2</td>
                    
                    <td>19.081</td>
                    
                    <td>9.54</td>
                    
                    <td>9.681</td>
                    
                    <td>9.4</td>
                    
                    <td>2</td>
                    
                    <td>1.129</td>
                    
                    <td>1.129</td>
                    
                </tr>
                
                <tr>
                    
                    <td>43</td>
                    
                    <td>Fill</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>15.881</td>
                    
                    <td>1.444</td>
                    
                    <td>1.6</td>
                    
                    <td>1.3</td>
                    
                    <td>11</td>
                    
                    <td>6.52</td>
                    
                    <td>1.63</td>
                    
                    <td>1.88</td>
                    
                    <td>1.42</td>
                    
                    <td>4</td>
                    
                    <td>0.4106</td>
                    
                    <td>1.1288</td>
                    
                </tr>
                
                <tr>
                    
                    <td>38</td>
                    
                    <td>LinearIndexV2</td>
                    
                    <td>MIX_AIV</td>
                    
                    <td>121.502</td>
                    
                    <td>20.25</td>
                    
                    <td>20.86</td>
                    
                    <td>18.881</td>
                    
                    <td>6</td>
                    
                    <td>90.682</td>
                    
                    <td>22.671</td>
                    
                    <td>24.34</td>
                    
                    <td>21.541</td>
                    
                    <td>4</td>
                    
                    <td>0.7463</td>
                    
                    <td>1.1196</td>
                    
                </tr>
                
                <tr>
                    
                    <td>5</td>
                    
                    <td>Less</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>21.441</td>
                    
                    <td>10.72</td>
                    
                    <td>11.28</td>
                    
                    <td>10.161</td>
                    
                    <td>2</td>
                    
                    <td>23.921</td>
                    
                    <td>11.96</td>
                    
                    <td>12.581</td>
                    
                    <td>11.34</td>
                    
                    <td>2</td>
                    
                    <td>1.1157</td>
                    
                    <td>1.1157</td>
                    
                </tr>
                
                <tr>
                    
                    <td>6</td>
                    
                    <td>Addcmul</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>11961.336</td>
                    
                    <td>35.18</td>
                    
                    <td>889.337</td>
                    
                    <td>2.0</td>
                    
                    <td>340</td>
                    
                    <td>12491.693</td>
                    
                    <td>36.958</td>
                    
                    <td>895.998</td>
                    
                    <td>2.04</td>
                    
                    <td>338</td>
                    
                    <td>1.0443</td>
                    
                    <td>1.0505</td>
                    
                </tr>
                
                <tr>
                    
                    <td>7</td>
                    
                    <td>Addcdiv</td>
                    
                    <td>AI_VECTOR_CORE</td>
                    
                    <td>13155.317</td>
                    
                    <td>38.692</td>
                    
                    <td>1144.902</td>
                    
                    <td>1.94</td>
                    
                    <td>340</td>
                    
                    <td>13414.21</td>
                    
                    <td>39.687</td>
                    
                    <td>1141.842</td>
                    
                    <td>1.98</td>
                    
                    <td>338</td>
                    
                    <td>1.0197</td>
                    
                    <td>1.0257</td>
                    
                </tr>
                
            </table>

        </div>
</div>

            
            
<div class="collapsible">
      <h2 class="collapsible-header" style="background-color: ;">Api compare of Rank6 Step0 and Rank11 Step0</h2>
      <div class="collapsible-content">
            <a style="font-weight: bold" id="timeline_api_instruction_issue">Issue: Api compare of Rank6 Step0 and Rank11 Step0. Only show 10 rows here, see mstt_advisor*.xlsx for details</a>
            <br><br>
            <table>
                <tr>
                
                    <th> Order Id </th>
                
                    <th> api name </th>
                
                    <th> Total Duration(ms) </th>
                
                    <th> Self Time(ms) </th>
                
                    <th> Avg Duration(ms) </th>
                
                    <th> Calls </th>
                
                    <th> Benchmark  Total Duration(ms) </th>
                
                    <th> Benchmark  Self Time(ms) </th>
                
                    <th> Benchmark  Avg Duration(ms) </th>
                
                    <th> Benchmark  Calls </th>
                
                    <th> Diff Total Ratio </th>
                
                    <th> Diff Self Ratio </th>
                
                    <th> Diff Avg Ratio </th>
                
                    <th> Diff Calls Ratio </th>
                
                </tr>

                
                <tr>
                    
                    <td>229</td>
                    
                    <td>aten::embedding</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>14.49</td>
                    
                    <td>13.97</td>
                    
                    <td>7.25</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>230</td>
                    
                    <td>_ReduceForward</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>3.49</td>
                    
                    <td>1.66</td>
                    
                    <td>1.75</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>231</td>
                    
                    <td>_SplitForwardGatherBackward</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>4.24</td>
                    
                    <td>1.03</td>
                    
                    <td>2.12</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>232</td>
                    
                    <td>autograd::engine::evaluate_function: _SplitForwardGatherBackwardBackward</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>3.28</td>
                    
                    <td>0.05</td>
                    
                    <td>1.64</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>233</td>
                    
                    <td>autograd::engine::evaluate_function: _ReduceForwardBackward</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>0.08</td>
                    
                    <td>0.02</td>
                    
                    <td>0.04</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>234</td>
                    
                    <td>autograd::engine::evaluate_function: torch::autograd::CopySlices</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>38440.37</td>
                    
                    <td>0.24</td>
                    
                    <td>19220.19</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>235</td>
                    
                    <td>autograd::engine::evaluate_function: EmbeddingBackward0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>5.91</td>
                    
                    <td>0.06</td>
                    
                    <td>2.96</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>236</td>
                    
                    <td>aclnnEmbedding</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>0.18</td>
                    
                    <td>0.18</td>
                    
                    <td>0.09</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>237</td>
                    
                    <td>_SplitForwardGatherBackwardBackward</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>3.24</td>
                    
                    <td>0.39</td>
                    
                    <td>1.62</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
                <tr>
                    
                    <td>238</td>
                    
                    <td>_ReduceForwardBackward</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0.0</td>
                    
                    <td>0</td>
                    
                    <td>0.06</td>
                    
                    <td>0.06</td>
                    
                    <td>0.03</td>
                    
                    <td>2</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                    <td>inf</td>
                    
                </tr>
                
            </table>

        </div>
</div>

            
        </div>
    </div>
    

    

    <div class="collapsible">
      <h2 class="collapsible-header">performance problem analysis</h2>
      <div class="collapsible-content">


      
        <div class="collapsible">
          <h2 class="collapsible-header">memory</h2>
          <div class="collapsible-content">
            
            <div class="collapsible">
  <h2 class="collapsible-header" style="background-color: #65c294;">Memory Operator Issues</h2>
  <div class="collapsible-content">
  
  <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 6. </a>
  
    <a style="font-weight: bold" id="timeline_api_instruction">发现了243个AscendCL@aclMallocMemInner算子，花费55469.200000000004us，这将导致大量的空闲时间。 </a>
    <table>
        <tr>
            <th>Suggestions</th>
        </tr>

        
            <tr>
                <td>1. For AscendCL@aclMallocMemInner: 请通过命令'export PYTORCH_NPU_ALLOC_CONF=expandable_segments:True'设置环境变量，然后开始训练任务。</td>
            </tr>
        
    </table>

  </div>
</div>
            
          </div>
        </div>
      
        <div class="collapsible">
          <h2 class="collapsible-header">computation</h2>
          <div class="collapsible-content">
            
            
<div class="collapsible">
    <h2 class="collapsible-header">Pipeline Parallel Stages Issues</h2>
    <div class="collapsible-content">
      
      <div class="collapsible">
          <h2 class="collapsible-header">stage-0</h2>
          <div class="collapsible-content">
                <a style="font-weight: bold" id="timeline_api_instruction">Description: analysis for slow rank 4 in current stage</a>
                <br><br>
                
                    <div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">Operator Dynamic Shape Issues</h2>
    <div class="collapsible-content">
        
        <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 4. </a>
        
        <table>
            <tr>
                <th>Description</th>
                <th>Suggestion</th>
            </tr>
            <tr>
                <td>找到所有是动态shape的算子</td>
                <td>在python脚本入口加入以下代码关闭在线编译：<br>'torch_npu.npu.set_compile_mode(jit_compile=False) <br> torch_npu.npu.config.allow_internal_format = False' <br>详细信息请参考：<a href=https://www.hiascend.com/document/detail/zh/canncommercial/700/modeldevpt/ptmigr/AImpug_000060.html target='_blank'>链接</a></td>
            </tr>
        </table>
    </div>
</div>
                
                    <div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">AICPU Issues</h2>
    <div class="collapsible-content">
        
        <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 4. </a>
        
        <table>
            <tr>
                <th>Description</th>
                <th>Suggestion</th>
                <th>Elapsed Time(us)</th>
                <th>Time Ratio</th>
            </tr>
            <tr>
                <td>一些算子和任务执行时间超过了20us，比如：
IndexPut</td>
                <td>修改代码避免使用aicpu类算子</td>
                <td>12336.79</td>
                <td>0.0003</td>
            </tr>
        </table>
        <div class="collapsible">
            
            <div class="collapsible-header">IndexPut</div>
            <div class="collapsible-content">
                <table>
                    <tr>
                        <th>Operator Type</th>
                        <th>Counts</th>
                        <th>Elapsed Time(us)</th>
                    </tr>
                    <tr>
                        <td>IndexPut</td>
                        <td>2</td>
                        <td>12336.79</td>
                    </tr>
                </table>
                <div class="collapsible">
                    
                    <div class="collapsible-header">
                        <b>IndexPut</b> | Input DType:(INT64;INT64;INT64;INT64) | Output DType:(INT64) | Counts:2 | Elapsed Time(us):12336.79
                    </div>
                    <div class="collapsible-content">
                        
                        <div>
                            
                            <p>
                                <b>Suggestion 1:</b> <u>请参考<a href='https://gitee.com/ascend/mstt/blob/master/profiler/msprof_analyze/advisor/doc/Samples%20of%20AI%20CPU%20Operator%20Replacement.md' target='_blank'>链接</a>修改源码，尝试用等价的算子替换indexput算子。</u>
                            </p>
                            
                        </div>
                        
                        <div class="separator"></div>
                        <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(84): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(249): cross_entropy_1d;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(334): dist_cross_entropy;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(360): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): <module></a>
                    </div>
                    
                </div>
            </div>
            
        </div>
    </div>
</div>
                
                    
<div class="collapsible">
      <h2 class="collapsible-header" style="background-color: #B5495B;">AI Core Frequency Issues</h2>
      <div class="collapsible-content">
            
            <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 4. </a>
            
            <a style="font-weight: bold" id="timeline_api_instruction_issue">Issue: 对于4号卡，在降频期间发现1个算子，频率降低比例超过了0.05。 Only show 10 operators here, see latest mstt_advisor.xlsx for details.</a>
            <br>
            <a style="font-weight: bold" id="timeline_api_suggestion">Suggestion: </a>
            <br><br>
            <table>
                <tr>
                
                    <th> Operator name </th>
                
                    <th> Count </th>
                
                    <th> Total duration(us) </th>
                
                    <th> AI CORE frequency decreased ratio </th>
                
                    <th> Average frequency </th>
                
                    <th> Max frequency </th>
                
                    <th> Min frequency </th>
                
                </tr>

                
                <tr>
                    
                    <td>aclnnInplaceFillScalar_FillAiCore_Fill</td>
                    
                    <td>11</td>
                    
                    <td>15.88</td>
                    
                    <td>5.05%</td>
                    
                    <td>1709.09</td>
                    
                    <td>1800.0</td>
                    
                    <td>800.0</td>
                    
                </tr>
                
            </table>

        </div>
</div>

                
                    
<style>
    .typecol {
        width: 30%;
    }
</style>
<div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">AI Core Performance Analysis</h2>
    <div class="collapsible-content">
        
        
        
        
        <a style="font-weight: bold" id="cube_analyze">Cube算子相关分析，参考如下: </a>
        <br>
        <table>
            <tr>
                <th class="typecol">类别</th>
                <th>描述及建议</th>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>性能优化算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> 参考性能优化空间</th></tr>
                    <tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;4736,3584</td><td>DT_BF16;DT_BF16</td><td>9.59%</td></tr><tr><td>aclnnAddmm_MatMulCommon_MatMulV2</td><td>16384,3584;896,3584;896</td><td>DT_BF16;DT_BF16;FLOAT</td><td>9.58%</td></tr><tr><td>aclnnAddmm_MatMulCommon_MatMulV2</td><td>16384,3584;128,3584;128</td><td>DT_BF16;DT_BF16;FLOAT</td><td>4.92%</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;38016,3584</td><td>DT_BF16;DT_BF16</td><td>1.9%</td></tr></tr>
                </table>
                </td>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>不亲和算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> 不亲和类型为</th></tr>
                    <tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;16384,3584</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;4736,3584</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;16384,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;3584,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;3584,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr></tr>
                </table>
                </td>
            </tr>
            
        </table>
        

        
        <a style="font-weight: bold" id="fa_analyze">FA算子相关分析，参考如下: </a>
        <br>
        <table>
            <tr>
                <th class="typecol">类别</th>
                <th>描述及建议</th>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>bound算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> bound类型为</th></tr>
                    <tr><tr><td>aclnnFlashAttentionScoreGrad_FlashAttentionScoreGrad_FlashAttentionScoreGrad</td><td>1,7,16384,128;1,7,16384,128;1,7,16384,128;1,7,16384,128;16384,16384;1,7,16384,8;1,7,16384,8;;1,7,16384,128;</td><td>DT_BF16;DT_BF16;DT_BF16;DT_BF16;BOOL;FLOAT;FLOAT;DT_BF16;DT_BF16;INT64</td><td>fixpipe</td></tr><tr><td>aclnnFlashAttentionScore_FlashAttentionScore_FlashAttentionScore</td><td>1,7,16384,128;1,7,16384,128;1,7,16384,128;;;;16384,16384;;;;;</td><td>None</td><td>vec</td></tr></tr>
                </table>
                </td>
            </tr>
            
            
            
            
        </table>
        

        
    </div>
</div>

                
          </div>
      </div>
      
      <div class="collapsible">
          <h2 class="collapsible-header">stage-1</h2>
          <div class="collapsible-content">
                <a style="font-weight: bold" id="timeline_api_instruction">Description: analysis for slow rank 5 in current stage</a>
                <br><br>
                
                    <div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">Operator Dynamic Shape Issues</h2>
    <div class="collapsible-content">
        
        <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 5. </a>
        
        <table>
            <tr>
                <th>Description</th>
                <th>Suggestion</th>
            </tr>
            <tr>
                <td>找到所有是动态shape的算子</td>
                <td>在python脚本入口加入以下代码关闭在线编译：<br>'torch_npu.npu.set_compile_mode(jit_compile=False) <br> torch_npu.npu.config.allow_internal_format = False' <br>详细信息请参考：<a href=https://www.hiascend.com/document/detail/zh/canncommercial/700/modeldevpt/ptmigr/AImpug_000060.html target='_blank'>链接</a></td>
            </tr>
        </table>
    </div>
</div>
                
                    <div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">AICPU Issues</h2>
    <div class="collapsible-content">
        
        <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 5. </a>
        
        <table>
            <tr>
                <th>Description</th>
                <th>Suggestion</th>
                <th>Elapsed Time(us)</th>
                <th>Time Ratio</th>
            </tr>
            <tr>
                <td>一些算子和任务执行时间超过了20us，比如：
IndexPut</td>
                <td>修改代码避免使用aicpu类算子</td>
                <td>12350.77</td>
                <td>0.0002</td>
            </tr>
        </table>
        <div class="collapsible">
            
            <div class="collapsible-header">IndexPut</div>
            <div class="collapsible-content">
                <table>
                    <tr>
                        <th>Operator Type</th>
                        <th>Counts</th>
                        <th>Elapsed Time(us)</th>
                    </tr>
                    <tr>
                        <td>IndexPut</td>
                        <td>2</td>
                        <td>12350.77</td>
                    </tr>
                </table>
                <div class="collapsible">
                    
                    <div class="collapsible-header">
                        <b>IndexPut</b> | Input DType:(INT64;INT64;INT64;INT64) | Output DType:(INT64) | Counts:2 | Elapsed Time(us):12350.77
                    </div>
                    <div class="collapsible-content">
                        
                        <div>
                            
                            <p>
                                <b>Suggestion 1:</b> <u>请参考<a href='https://gitee.com/ascend/mstt/blob/master/profiler/msprof_analyze/advisor/doc/Samples%20of%20AI%20CPU%20Operator%20Replacement.md' target='_blank'>链接</a>修改源码，尝试用等价的算子替换indexput算子。</u>
                            </p>
                            
                        </div>
                        
                        <div class="separator"></div>
                        <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(84): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(249): cross_entropy_1d;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(334): dist_cross_entropy;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(360): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): <module></a>
                    </div>
                    
                </div>
            </div>
            
        </div>
    </div>
</div>
                
                    
<style>
    .typecol {
        width: 30%;
    }
</style>
<div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">AI Core Performance Analysis</h2>
    <div class="collapsible-content">
        
        
        
        
        <a style="font-weight: bold" id="cube_analyze">Cube算子相关分析，参考如下: </a>
        <br>
        <table>
            <tr>
                <th class="typecol">类别</th>
                <th>描述及建议</th>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>性能优化算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> 参考性能优化空间</th></tr>
                    <tr><tr><td>aclnnAddmm_MatMulCommon_MatMulV2</td><td>16384,3584;896,3584;896</td><td>DT_BF16;DT_BF16;FLOAT</td><td>9.65%</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;4736,3584</td><td>DT_BF16;DT_BF16</td><td>9.49%</td></tr><tr><td>aclnnAddmm_MatMulCommon_MatMulV2</td><td>16384,3584;128,3584;128</td><td>DT_BF16;DT_BF16;FLOAT</td><td>4.55%</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;38016,3584</td><td>DT_BF16;DT_BF16</td><td>1.85%</td></tr></tr>
                </table>
                </td>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>不亲和算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> 不亲和类型为</th></tr>
                    <tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;16384,3584</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;4736,3584</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;16384,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;3584,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;3584,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr></tr>
                </table>
                </td>
            </tr>
            
        </table>
        

        
        <a style="font-weight: bold" id="fa_analyze">FA算子相关分析，参考如下: </a>
        <br>
        <table>
            <tr>
                <th class="typecol">类别</th>
                <th>描述及建议</th>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>bound算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> bound类型为</th></tr>
                    <tr><tr><td>aclnnFlashAttentionScoreGrad_FlashAttentionScoreGrad_FlashAttentionScoreGrad</td><td>1,7,16384,128;1,7,16384,128;1,7,16384,128;1,7,16384,128;16384,16384;1,7,16384,8;1,7,16384,8;;1,7,16384,128;</td><td>DT_BF16;DT_BF16;DT_BF16;DT_BF16;BOOL;FLOAT;FLOAT;DT_BF16;DT_BF16;INT64</td><td>fixpipe</td></tr><tr><td>aclnnFlashAttentionScore_FlashAttentionScore_FlashAttentionScore</td><td>1,7,16384,128;1,7,16384,128;1,7,16384,128;;;;16384,16384;;;;;</td><td>None</td><td>vec</td></tr></tr>
                </table>
                </td>
            </tr>
            
            
            
            
        </table>
        

        
    </div>
</div>

                
          </div>
      </div>
      
      <div class="collapsible">
          <h2 class="collapsible-header">stage-2</h2>
          <div class="collapsible-content">
                <a style="font-weight: bold" id="timeline_api_instruction">Description: analysis for slow rank 6 in current stage</a>
                <br><br>
                
                    <div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">Operator Dynamic Shape Issues</h2>
    <div class="collapsible-content">
        
        <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 6. </a>
        
        <table>
            <tr>
                <th>Description</th>
                <th>Suggestion</th>
            </tr>
            <tr>
                <td>找到所有是动态shape的算子</td>
                <td>在python脚本入口加入以下代码关闭在线编译：<br>'torch_npu.npu.set_compile_mode(jit_compile=False) <br> torch_npu.npu.config.allow_internal_format = False' <br>详细信息请参考：<a href=https://www.hiascend.com/document/detail/zh/canncommercial/700/modeldevpt/ptmigr/AImpug_000060.html target='_blank'>链接</a></td>
            </tr>
        </table>
    </div>
</div>
                
                    <div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">AICPU Issues</h2>
    <div class="collapsible-content">
        
        <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 6. </a>
        
        <table>
            <tr>
                <th>Description</th>
                <th>Suggestion</th>
                <th>Elapsed Time(us)</th>
                <th>Time Ratio</th>
            </tr>
            <tr>
                <td>一些算子和任务执行时间超过了20us，比如：
IndexPut</td>
                <td>修改代码避免使用aicpu类算子</td>
                <td>12259.62</td>
                <td>0.0024</td>
            </tr>
        </table>
        <div class="collapsible">
            
            <div class="collapsible-header">IndexPut</div>
            <div class="collapsible-content">
                <table>
                    <tr>
                        <th>Operator Type</th>
                        <th>Counts</th>
                        <th>Elapsed Time(us)</th>
                    </tr>
                    <tr>
                        <td>IndexPut</td>
                        <td>2</td>
                        <td>12259.62</td>
                    </tr>
                </table>
                <div class="collapsible">
                    
                    <div class="collapsible-header">
                        <b>IndexPut</b> | Input DType:(INT64;INT64;INT64;INT64) | Output DType:(INT64) | Counts:2 | Elapsed Time(us):12259.62
                    </div>
                    <div class="collapsible-content">
                        
                        <div>
                            
                            <p>
                                <b>Suggestion 1:</b> <u>请参考<a href='https://gitee.com/ascend/mstt/blob/master/profiler/msprof_analyze/advisor/doc/Samples%20of%20AI%20CPU%20Operator%20Replacement.md' target='_blank'>链接</a>修改源码，尝试用等价的算子替换indexput算子。</u>
                            </p>
                            
                        </div>
                        
                        <div class="separator"></div>
                        <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(84): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(249): cross_entropy_1d;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(334): dist_cross_entropy;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(360): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): <module></a>
                    </div>
                    
                </div>
            </div>
            
        </div>
    </div>
</div>
                
                    
<style>
    .typecol {
        width: 30%;
    }
</style>
<div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">AI Core Performance Analysis</h2>
    <div class="collapsible-content">
        
        
        
        
        <a style="font-weight: bold" id="cube_analyze">Cube算子相关分析，参考如下: </a>
        <br>
        <table>
            <tr>
                <th class="typecol">类别</th>
                <th>描述及建议</th>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>性能优化算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> 参考性能优化空间</th></tr>
                    <tr><tr><td>aclnnAddmm_MatMulCommon_MatMulV2</td><td>16384,3584;896,3584;896</td><td>DT_BF16;DT_BF16;FLOAT</td><td>9.69%</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;4736,3584</td><td>DT_BF16;DT_BF16</td><td>9.49%</td></tr><tr><td>aclnnAddmm_MatMulCommon_MatMulV2</td><td>16384,3584;128,3584;128</td><td>DT_BF16;DT_BF16;FLOAT</td><td>4.94%</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;38016,3584</td><td>DT_BF16;DT_BF16</td><td>1.95%</td></tr></tr>
                </table>
                </td>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>不亲和算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> 不亲和类型为</th></tr>
                    <tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;16384,3584</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;4736,3584</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;16384,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;3584,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;3584,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr></tr>
                </table>
                </td>
            </tr>
            
        </table>
        

        
        <a style="font-weight: bold" id="fa_analyze">FA算子相关分析，参考如下: </a>
        <br>
        <table>
            <tr>
                <th class="typecol">类别</th>
                <th>描述及建议</th>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>bound算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> bound类型为</th></tr>
                    <tr><tr><td>aclnnFlashAttentionScoreGrad_FlashAttentionScoreGrad_FlashAttentionScoreGrad</td><td>1,7,16384,128;1,7,16384,128;1,7,16384,128;1,7,16384,128;16384,16384;1,7,16384,8;1,7,16384,8;;1,7,16384,128;</td><td>DT_BF16;DT_BF16;DT_BF16;DT_BF16;BOOL;FLOAT;FLOAT;DT_BF16;DT_BF16;INT64</td><td>fixpipe</td></tr><tr><td>aclnnFlashAttentionScore_FlashAttentionScore_FlashAttentionScore</td><td>1,7,16384,128;1,7,16384,128;1,7,16384,128;;;;16384,16384;;;;;</td><td>None</td><td>vec</td></tr></tr>
                </table>
                </td>
            </tr>
            
            
            
            
        </table>
        

        
        <a style="font-weight: bold" id="vector_analyze">Vector算子相关分析，参考如下: </a>
        <br>
        <table>
            <tr>
                <th class="typecol">类别</th>
                <th>描述及建议</th>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>性能优化算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> 参考性能优化空间</th></tr>
                    <tr><tr><td>aclnnInplaceCopy_TensorMoveAiCore_TensorMove</td><td>3584,4736</td><td>DT_BF16</td><td>70.0%</td></tr><tr><td>aclnnInplaceCopy_TensorMoveAiCore_TensorMove</td><td>896,3584</td><td>DT_BF16</td><td>69.9%</td></tr><tr><td>aclnnInplaceCopy_TensorMoveAiCore_TensorMove</td><td>3584,896</td><td>DT_BF16</td><td>69.88%</td></tr><tr><td>aclnnInplaceCopy_TensorMoveAiCore_TensorMove</td><td>1,1,1,16384,128</td><td>DT_BF16</td><td>69.82%</td></tr><tr><td>aclnnInplaceCopy_TensorMoveAiCore_TensorMove</td><td>1,1,16384,128</td><td>DT_BF16</td><td>69.8%</td></tr></tr>
                </table>
                </td>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>bound算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> bound类型为</th></tr>
                    <tr><tr><td>aclnnInplaceCopy_TensorMoveAiCore_TensorMove</td><td>1,4096,3584</td><td>DT_BF16</td><td>vec_mte2_mte3</td></tr><tr><td>aclnnMul_MulAiCore_Mul</td><td>1,16384,4736;1,16384,4736</td><td>DT_BF16;DT_BF16</td><td>vec_mte2_mte3</td></tr><tr><td>aclnnMul_MulAiCore_Mul</td><td>1,4096,3584;1,4096,3584</td><td>FLOAT;FLOAT</td><td>vec_mte2_mte3</td></tr><tr><td>aclnnInplaceMul_CastAiCore_Cast</td><td>16383,38016</td><td>FLOAT</td><td>vec_mte2_mte3</td></tr><tr><td>aclnnInplaceMuls_MulAiCore_Mul</td><td>8486912;</td><td>FLOAT;FLOAT</td><td>vec_mte2_mte3</td></tr></tr>
                </table>
                </td>
            </tr>
            
        </table>
        
    </div>
</div>

                
          </div>
      </div>
      
      <div class="collapsible">
          <h2 class="collapsible-header">stage-3</h2>
          <div class="collapsible-content">
                <a style="font-weight: bold" id="timeline_api_instruction">Description: analysis for slow rank 7 in current stage</a>
                <br><br>
                
                    <div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">Operator Dynamic Shape Issues</h2>
    <div class="collapsible-content">
        
        <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 7. </a>
        
        <table>
            <tr>
                <th>Description</th>
                <th>Suggestion</th>
            </tr>
            <tr>
                <td>找到所有是动态shape的算子</td>
                <td>在python脚本入口加入以下代码关闭在线编译：<br>'torch_npu.npu.set_compile_mode(jit_compile=False) <br> torch_npu.npu.config.allow_internal_format = False' <br>详细信息请参考：<a href=https://www.hiascend.com/document/detail/zh/canncommercial/700/modeldevpt/ptmigr/AImpug_000060.html target='_blank'>链接</a></td>
            </tr>
        </table>
    </div>
</div>
                
                    <div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">AICPU Issues</h2>
    <div class="collapsible-content">
        
        <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 7. </a>
        
        <table>
            <tr>
                <th>Description</th>
                <th>Suggestion</th>
                <th>Elapsed Time(us)</th>
                <th>Time Ratio</th>
            </tr>
            <tr>
                <td>一些算子和任务执行时间超过了20us，比如：
IndexPut</td>
                <td>修改代码避免使用aicpu类算子</td>
                <td>12304.89</td>
                <td>0.0002</td>
            </tr>
        </table>
        <div class="collapsible">
            
            <div class="collapsible-header">IndexPut</div>
            <div class="collapsible-content">
                <table>
                    <tr>
                        <th>Operator Type</th>
                        <th>Counts</th>
                        <th>Elapsed Time(us)</th>
                    </tr>
                    <tr>
                        <td>IndexPut</td>
                        <td>2</td>
                        <td>12304.89</td>
                    </tr>
                </table>
                <div class="collapsible">
                    
                    <div class="collapsible-header">
                        <b>IndexPut</b> | Input DType:(INT64;INT64;INT64;INT64) | Output DType:(INT64) | Counts:2 | Elapsed Time(us):12304.89
                    </div>
                    <div class="collapsible-content">
                        
                        <div>
                            
                            <p>
                                <b>Suggestion 1:</b> <u>请参考<a href='https://gitee.com/ascend/mstt/blob/master/profiler/msprof_analyze/advisor/doc/Samples%20of%20AI%20CPU%20Operator%20Replacement.md' target='_blank'>链接</a>修改源码，尝试用等价的算子替换indexput算子。</u>
                            </p>
                            
                        </div>
                        
                        <div class="separator"></div>
                        <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(84): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(249): cross_entropy_1d;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(334): dist_cross_entropy;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(360): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): <module></a>
                    </div>
                    
                </div>
            </div>
            
        </div>
    </div>
</div>
                
                    
<style>
    .typecol {
        width: 30%;
    }
</style>
<div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">AI Core Performance Analysis</h2>
    <div class="collapsible-content">
        
        
        
        
        <a style="font-weight: bold" id="cube_analyze">Cube算子相关分析，参考如下: </a>
        <br>
        <table>
            <tr>
                <th class="typecol">类别</th>
                <th>描述及建议</th>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>性能优化算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> 参考性能优化空间</th></tr>
                    <tr><tr><td>aclnnAddmm_MatMulCommon_MatMulV2</td><td>16384,3584;896,3584;896</td><td>DT_BF16;DT_BF16;FLOAT</td><td>9.68%</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;4736,3584</td><td>DT_BF16;DT_BF16</td><td>9.51%</td></tr><tr><td>aclnnAddmm_MatMulCommon_MatMulV2</td><td>16384,3584;128,3584;128</td><td>DT_BF16;DT_BF16;FLOAT</td><td>4.76%</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;38016,3584</td><td>DT_BF16;DT_BF16</td><td>1.85%</td></tr></tr>
                </table>
                </td>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>不亲和算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> 不亲和类型为</th></tr>
                    <tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;16384,3584</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;4736,3584</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;16384,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;3584,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;3584,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr></tr>
                </table>
                </td>
            </tr>
            
        </table>
        

        
        <a style="font-weight: bold" id="fa_analyze">FA算子相关分析，参考如下: </a>
        <br>
        <table>
            <tr>
                <th class="typecol">类别</th>
                <th>描述及建议</th>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>bound算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> bound类型为</th></tr>
                    <tr><tr><td>aclnnFlashAttentionScoreGrad_FlashAttentionScoreGrad_FlashAttentionScoreGrad</td><td>1,7,16384,128;1,7,16384,128;1,7,16384,128;1,7,16384,128;16384,16384;1,7,16384,8;1,7,16384,8;;1,7,16384,128;</td><td>DT_BF16;DT_BF16;DT_BF16;DT_BF16;BOOL;FLOAT;FLOAT;DT_BF16;DT_BF16;INT64</td><td>fixpipe</td></tr><tr><td>aclnnFlashAttentionScore_FlashAttentionScore_FlashAttentionScore</td><td>1,7,16384,128;1,7,16384,128;1,7,16384,128;;;;16384,16384;;;;;</td><td>None</td><td>vec</td></tr></tr>
                </table>
                </td>
            </tr>
            
            
            
            
        </table>
        

        
    </div>
</div>

                
          </div>
      </div>
      
      <div class="collapsible">
          <h2 class="collapsible-header">stage-4</h2>
          <div class="collapsible-content">
                <a style="font-weight: bold" id="timeline_api_instruction">Description: analysis for slow rank 12 in current stage</a>
                <br><br>
                
                    <div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">Operator Dynamic Shape Issues</h2>
    <div class="collapsible-content">
        
        <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 12. </a>
        
        <table>
            <tr>
                <th>Description</th>
                <th>Suggestion</th>
            </tr>
            <tr>
                <td>找到所有是动态shape的算子</td>
                <td>在python脚本入口加入以下代码关闭在线编译：<br>'torch_npu.npu.set_compile_mode(jit_compile=False) <br> torch_npu.npu.config.allow_internal_format = False' <br>详细信息请参考：<a href=https://www.hiascend.com/document/detail/zh/canncommercial/700/modeldevpt/ptmigr/AImpug_000060.html target='_blank'>链接</a></td>
            </tr>
        </table>
    </div>
</div>
                
                    <div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">AICPU Issues</h2>
    <div class="collapsible-content">
        
        <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 12. </a>
        
        <table>
            <tr>
                <th>Description</th>
                <th>Suggestion</th>
                <th>Elapsed Time(us)</th>
                <th>Time Ratio</th>
            </tr>
            <tr>
                <td>一些算子和任务执行时间超过了20us，比如：
IndexPut</td>
                <td>修改代码避免使用aicpu类算子</td>
                <td>12328.43</td>
                <td>0.0002</td>
            </tr>
        </table>
        <div class="collapsible">
            
            <div class="collapsible-header">IndexPut</div>
            <div class="collapsible-content">
                <table>
                    <tr>
                        <th>Operator Type</th>
                        <th>Counts</th>
                        <th>Elapsed Time(us)</th>
                    </tr>
                    <tr>
                        <td>IndexPut</td>
                        <td>2</td>
                        <td>12328.43</td>
                    </tr>
                </table>
                <div class="collapsible">
                    
                    <div class="collapsible-header">
                        <b>IndexPut</b> | Input DType:(INT64;INT64;INT64;INT64) | Output DType:(INT64) | Counts:2 | Elapsed Time(us):12328.43
                    </div>
                    <div class="collapsible-content">
                        
                        <div>
                            
                            <p>
                                <b>Suggestion 1:</b> <u>请参考<a href='https://gitee.com/ascend/mstt/blob/master/profiler/msprof_analyze/advisor/doc/Samples%20of%20AI%20CPU%20Operator%20Replacement.md' target='_blank'>链接</a>修改源码，尝试用等价的算子替换indexput算子。</u>
                            </p>
                            
                        </div>
                        
                        <div class="separator"></div>
                        <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(84): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(249): cross_entropy_1d;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(334): dist_cross_entropy;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(360): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): <module></a>
                    </div>
                    
                </div>
            </div>
            
        </div>
    </div>
</div>
                
                    
<style>
    .typecol {
        width: 30%;
    }
</style>
<div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">AI Core Performance Analysis</h2>
    <div class="collapsible-content">
        
        
        
        
        <a style="font-weight: bold" id="cube_analyze">Cube算子相关分析，参考如下: </a>
        <br>
        <table>
            <tr>
                <th class="typecol">类别</th>
                <th>描述及建议</th>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>性能优化算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> 参考性能优化空间</th></tr>
                    <tr><tr><td>aclnnAddmm_MatMulCommon_MatMulV2</td><td>16384,3584;896,3584;896</td><td>DT_BF16;DT_BF16;FLOAT</td><td>9.58%</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;4736,3584</td><td>DT_BF16;DT_BF16</td><td>9.44%</td></tr><tr><td>aclnnAddmm_MatMulCommon_MatMulV2</td><td>16384,3584;128,3584;128</td><td>DT_BF16;DT_BF16;FLOAT</td><td>4.6%</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;38016,3584</td><td>DT_BF16;DT_BF16</td><td>2.05%</td></tr></tr>
                </table>
                </td>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>不亲和算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> 不亲和类型为</th></tr>
                    <tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;16384,3584</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;4736,3584</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;16384,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;3584,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;3584,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr></tr>
                </table>
                </td>
            </tr>
            
        </table>
        

        
        <a style="font-weight: bold" id="fa_analyze">FA算子相关分析，参考如下: </a>
        <br>
        <table>
            <tr>
                <th class="typecol">类别</th>
                <th>描述及建议</th>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>bound算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> bound类型为</th></tr>
                    <tr><tr><td>aclnnFlashAttentionScoreGrad_FlashAttentionScoreGrad_FlashAttentionScoreGrad</td><td>1,7,16384,128;1,7,16384,128;1,7,16384,128;1,7,16384,128;16384,16384;1,7,16384,8;1,7,16384,8;;1,7,16384,128;</td><td>DT_BF16;DT_BF16;DT_BF16;DT_BF16;BOOL;FLOAT;FLOAT;DT_BF16;DT_BF16;INT64</td><td>fixpipe</td></tr><tr><td>aclnnFlashAttentionScore_FlashAttentionScore_FlashAttentionScore</td><td>1,7,16384,128;1,7,16384,128;1,7,16384,128;;;;16384,16384;;;;;</td><td>None</td><td>vec</td></tr></tr>
                </table>
                </td>
            </tr>
            
            
            
            
        </table>
        

        
    </div>
</div>

                
          </div>
      </div>
      
      <div class="collapsible">
          <h2 class="collapsible-header">stage-5</h2>
          <div class="collapsible-content">
                <a style="font-weight: bold" id="timeline_api_instruction">Description: analysis for slow rank 13 in current stage</a>
                <br><br>
                
                    <div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">Operator Dynamic Shape Issues</h2>
    <div class="collapsible-content">
        
        <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 13. </a>
        
        <table>
            <tr>
                <th>Description</th>
                <th>Suggestion</th>
            </tr>
            <tr>
                <td>找到所有是动态shape的算子</td>
                <td>在python脚本入口加入以下代码关闭在线编译：<br>'torch_npu.npu.set_compile_mode(jit_compile=False) <br> torch_npu.npu.config.allow_internal_format = False' <br>详细信息请参考：<a href=https://www.hiascend.com/document/detail/zh/canncommercial/700/modeldevpt/ptmigr/AImpug_000060.html target='_blank'>链接</a></td>
            </tr>
        </table>
    </div>
</div>
                
                    <div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">AICPU Issues</h2>
    <div class="collapsible-content">
        
        <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 13. </a>
        
        <table>
            <tr>
                <th>Description</th>
                <th>Suggestion</th>
                <th>Elapsed Time(us)</th>
                <th>Time Ratio</th>
            </tr>
            <tr>
                <td>一些算子和任务执行时间超过了20us，比如：
IndexPut</td>
                <td>修改代码避免使用aicpu类算子</td>
                <td>12306.05</td>
                <td>0.0031</td>
            </tr>
        </table>
        <div class="collapsible">
            
            <div class="collapsible-header">IndexPut</div>
            <div class="collapsible-content">
                <table>
                    <tr>
                        <th>Operator Type</th>
                        <th>Counts</th>
                        <th>Elapsed Time(us)</th>
                    </tr>
                    <tr>
                        <td>IndexPut</td>
                        <td>2</td>
                        <td>12306.05</td>
                    </tr>
                </table>
                <div class="collapsible">
                    
                    <div class="collapsible-header">
                        <b>IndexPut</b> | Input DType:(INT64;INT64;INT64;INT64) | Output DType:(INT64) | Counts:2 | Elapsed Time(us):12306.05
                    </div>
                    <div class="collapsible-content">
                        
                        <div>
                            
                            <p>
                                <b>Suggestion 1:</b> <u>请参考<a href='https://gitee.com/ascend/mstt/blob/master/profiler/msprof_analyze/advisor/doc/Samples%20of%20AI%20CPU%20Operator%20Replacement.md' target='_blank'>链接</a>修改源码，尝试用等价的算子替换indexput算子。</u>
                            </p>
                            
                        </div>
                        
                        <div class="separator"></div>
                        <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(84): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(249): cross_entropy_1d;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(334): dist_cross_entropy;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(360): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): <module></a>
                    </div>
                    
                </div>
            </div>
            
        </div>
    </div>
</div>
                
                    
<style>
    .typecol {
        width: 30%;
    }
</style>
<div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">AI Core Performance Analysis</h2>
    <div class="collapsible-content">
        
        
        
        
        <a style="font-weight: bold" id="cube_analyze">Cube算子相关分析，参考如下: </a>
        <br>
        <table>
            <tr>
                <th class="typecol">类别</th>
                <th>描述及建议</th>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>性能优化算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> 参考性能优化空间</th></tr>
                    <tr><tr><td>aclnnAddmm_MatMulCommon_MatMulV2</td><td>16384,3584;896,3584;896</td><td>DT_BF16;DT_BF16;FLOAT</td><td>9.61%</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;4736,3584</td><td>DT_BF16;DT_BF16</td><td>9.45%</td></tr><tr><td>aclnnAddmm_MatMulCommon_MatMulV2</td><td>16384,3584;128,3584;128</td><td>DT_BF16;DT_BF16;FLOAT</td><td>4.73%</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;38016,3584</td><td>DT_BF16;DT_BF16</td><td>1.85%</td></tr></tr>
                </table>
                </td>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>不亲和算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> 不亲和类型为</th></tr>
                    <tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;16384,3584</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;4736,3584</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;16384,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;3584,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;3584,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr></tr>
                </table>
                </td>
            </tr>
            
        </table>
        

        
        <a style="font-weight: bold" id="fa_analyze">FA算子相关分析，参考如下: </a>
        <br>
        <table>
            <tr>
                <th class="typecol">类别</th>
                <th>描述及建议</th>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>bound算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> bound类型为</th></tr>
                    <tr><tr><td>aclnnFlashAttentionScoreGrad_FlashAttentionScoreGrad_FlashAttentionScoreGrad</td><td>1,7,16384,128;1,7,16384,128;1,7,16384,128;1,7,16384,128;16384,16384;1,7,16384,8;1,7,16384,8;;1,7,16384,128;</td><td>DT_BF16;DT_BF16;DT_BF16;DT_BF16;BOOL;FLOAT;FLOAT;DT_BF16;DT_BF16;INT64</td><td>fixpipe</td></tr><tr><td>aclnnFlashAttentionScore_FlashAttentionScore_FlashAttentionScore</td><td>1,7,16384,128;1,7,16384,128;1,7,16384,128;;;;16384,16384;;;;;</td><td>None</td><td>vec</td></tr></tr>
                </table>
                </td>
            </tr>
            
            
            
            
        </table>
        

        
        <a style="font-weight: bold" id="vector_analyze">Vector算子相关分析，参考如下: </a>
        <br>
        <table>
            <tr>
                <th class="typecol">类别</th>
                <th>描述及建议</th>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>性能优化算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> 参考性能优化空间</th></tr>
                    <tr><tr><td>aclnnInplaceCopy_TensorMoveAiCore_TensorMove</td><td>3584,4736</td><td>DT_BF16</td><td>70.0%</td></tr><tr><td>aclnnInplaceCopy_TensorMoveAiCore_TensorMove</td><td>3584,896</td><td>DT_BF16</td><td>69.89%</td></tr><tr><td>aclnnInplaceCopy_TensorMoveAiCore_TensorMove</td><td>896,3584</td><td>DT_BF16</td><td>69.89%</td></tr><tr><td>aclnnInplaceCopy_TensorMoveAiCore_TensorMove</td><td>1,1,1,16384,128</td><td>DT_BF16</td><td>69.82%</td></tr><tr><td>aclnnInplaceCopy_TensorMoveAiCore_TensorMove</td><td>1,1,16384,128</td><td>DT_BF16</td><td>69.8%</td></tr></tr>
                </table>
                </td>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>bound算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> bound类型为</th></tr>
                    <tr><tr><td>aclnnInplaceCopy_TensorMoveAiCore_TensorMove</td><td>1,4096,3584</td><td>DT_BF16</td><td>vec_mte2_mte3</td></tr><tr><td>aclnnMul_MulAiCore_Mul</td><td>1,16384,4736;1,16384,4736</td><td>DT_BF16;DT_BF16</td><td>vec_mte2_mte3</td></tr><tr><td>aclnnMul_MulAiCore_Mul</td><td>1,4096,3584;1,4096,3584</td><td>FLOAT;FLOAT</td><td>vec_mte2_mte3</td></tr><tr><td>aclnnInplaceMul_CastAiCore_Cast</td><td>16383,38016</td><td>FLOAT</td><td>vec_mte2_mte3</td></tr><tr><td>aclnnInplaceMuls_MulAiCore_Mul</td><td>8486912;</td><td>FLOAT;FLOAT</td><td>vec_mte2_mte3</td></tr></tr>
                </table>
                </td>
            </tr>
            
        </table>
        
    </div>
</div>

                
          </div>
      </div>
      
      <div class="collapsible">
          <h2 class="collapsible-header">stage-6</h2>
          <div class="collapsible-content">
                <a style="font-weight: bold" id="timeline_api_instruction">Description: analysis for slow rank 14 in current stage</a>
                <br><br>
                
                    <div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">Operator Dynamic Shape Issues</h2>
    <div class="collapsible-content">
        
        <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 14. </a>
        
        <table>
            <tr>
                <th>Description</th>
                <th>Suggestion</th>
            </tr>
            <tr>
                <td>找到所有是动态shape的算子</td>
                <td>在python脚本入口加入以下代码关闭在线编译：<br>'torch_npu.npu.set_compile_mode(jit_compile=False) <br> torch_npu.npu.config.allow_internal_format = False' <br>详细信息请参考：<a href=https://www.hiascend.com/document/detail/zh/canncommercial/700/modeldevpt/ptmigr/AImpug_000060.html target='_blank'>链接</a></td>
            </tr>
        </table>
    </div>
</div>
                
                    <div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">AICPU Issues</h2>
    <div class="collapsible-content">
        
        <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 14. </a>
        
        <table>
            <tr>
                <th>Description</th>
                <th>Suggestion</th>
                <th>Elapsed Time(us)</th>
                <th>Time Ratio</th>
            </tr>
            <tr>
                <td>一些算子和任务执行时间超过了20us，比如：
IndexPut</td>
                <td>修改代码避免使用aicpu类算子</td>
                <td>12324.21</td>
                <td>0.0003</td>
            </tr>
        </table>
        <div class="collapsible">
            
            <div class="collapsible-header">IndexPut</div>
            <div class="collapsible-content">
                <table>
                    <tr>
                        <th>Operator Type</th>
                        <th>Counts</th>
                        <th>Elapsed Time(us)</th>
                    </tr>
                    <tr>
                        <td>IndexPut</td>
                        <td>2</td>
                        <td>12324.21</td>
                    </tr>
                </table>
                <div class="collapsible">
                    
                    <div class="collapsible-header">
                        <b>IndexPut</b> | Input DType:(INT64;INT64;INT64;INT64) | Output DType:(INT64) | Counts:2 | Elapsed Time(us):12324.21
                    </div>
                    <div class="collapsible-content">
                        
                        <div>
                            
                            <p>
                                <b>Suggestion 1:</b> <u>请参考<a href='https://gitee.com/ascend/mstt/blob/master/profiler/msprof_analyze/advisor/doc/Samples%20of%20AI%20CPU%20Operator%20Replacement.md' target='_blank'>链接</a>修改源码，尝试用等价的算子替换indexput算子。</u>
                            </p>
                            
                        </div>
                        
                        <div class="separator"></div>
                        <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(84): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(249): cross_entropy_1d;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(334): dist_cross_entropy;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(360): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): <module></a>
                    </div>
                    
                </div>
            </div>
            
        </div>
    </div>
</div>
                
                    
<style>
    .typecol {
        width: 30%;
    }
</style>
<div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">AI Core Performance Analysis</h2>
    <div class="collapsible-content">
        
        
        
        
        <a style="font-weight: bold" id="cube_analyze">Cube算子相关分析，参考如下: </a>
        <br>
        <table>
            <tr>
                <th class="typecol">类别</th>
                <th>描述及建议</th>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>性能优化算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> 参考性能优化空间</th></tr>
                    <tr><tr><td>aclnnAddmm_MatMulCommon_MatMulV2</td><td>16384,3584;896,3584;896</td><td>DT_BF16;DT_BF16;FLOAT</td><td>9.64%</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;4736,3584</td><td>DT_BF16;DT_BF16</td><td>9.49%</td></tr><tr><td>aclnnAddmm_MatMulCommon_MatMulV2</td><td>16384,3584;128,3584;128</td><td>DT_BF16;DT_BF16;FLOAT</td><td>4.86%</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;38016,3584</td><td>DT_BF16;DT_BF16</td><td>1.8%</td></tr></tr>
                </table>
                </td>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>不亲和算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> 不亲和类型为</th></tr>
                    <tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;16384,3584</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;4736,3584</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;16384,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;3584,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;3584,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr></tr>
                </table>
                </td>
            </tr>
            
        </table>
        

        
        <a style="font-weight: bold" id="fa_analyze">FA算子相关分析，参考如下: </a>
        <br>
        <table>
            <tr>
                <th class="typecol">类别</th>
                <th>描述及建议</th>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>bound算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> bound类型为</th></tr>
                    <tr><tr><td>aclnnFlashAttentionScoreGrad_FlashAttentionScoreGrad_FlashAttentionScoreGrad</td><td>1,7,16384,128;1,7,16384,128;1,7,16384,128;1,7,16384,128;16384,16384;1,7,16384,8;1,7,16384,8;;1,7,16384,128;</td><td>DT_BF16;DT_BF16;DT_BF16;DT_BF16;BOOL;FLOAT;FLOAT;DT_BF16;DT_BF16;INT64</td><td>fixpipe</td></tr><tr><td>aclnnFlashAttentionScore_FlashAttentionScore_FlashAttentionScore</td><td>1,7,16384,128;1,7,16384,128;1,7,16384,128;;;;16384,16384;;;;;</td><td>None</td><td>vec</td></tr></tr>
                </table>
                </td>
            </tr>
            
            
            
            
        </table>
        

        
    </div>
</div>

                
          </div>
      </div>
      
      <div class="collapsible">
          <h2 class="collapsible-header">stage-7</h2>
          <div class="collapsible-content">
                <a style="font-weight: bold" id="timeline_api_instruction">Description: analysis for slow rank 15 in current stage</a>
                <br><br>
                
                    <div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">Operator Dynamic Shape Issues</h2>
    <div class="collapsible-content">
        
        <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 15. </a>
        
        <table>
            <tr>
                <th>Description</th>
                <th>Suggestion</th>
            </tr>
            <tr>
                <td>找到所有是动态shape的算子</td>
                <td>在python脚本入口加入以下代码关闭在线编译：<br>'torch_npu.npu.set_compile_mode(jit_compile=False) <br> torch_npu.npu.config.allow_internal_format = False' <br>详细信息请参考：<a href=https://www.hiascend.com/document/detail/zh/canncommercial/700/modeldevpt/ptmigr/AImpug_000060.html target='_blank'>链接</a></td>
            </tr>
        </table>
    </div>
</div>
                
                    <div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">AICPU Issues</h2>
    <div class="collapsible-content">
        
        <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 15. </a>
        
        <table>
            <tr>
                <th>Description</th>
                <th>Suggestion</th>
                <th>Elapsed Time(us)</th>
                <th>Time Ratio</th>
            </tr>
            <tr>
                <td>一些算子和任务执行时间超过了20us，比如：
IndexPut</td>
                <td>修改代码避免使用aicpu类算子</td>
                <td>12297.57</td>
                <td>0.0002</td>
            </tr>
        </table>
        <div class="collapsible">
            
            <div class="collapsible-header">IndexPut</div>
            <div class="collapsible-content">
                <table>
                    <tr>
                        <th>Operator Type</th>
                        <th>Counts</th>
                        <th>Elapsed Time(us)</th>
                    </tr>
                    <tr>
                        <td>IndexPut</td>
                        <td>2</td>
                        <td>12297.57</td>
                    </tr>
                </table>
                <div class="collapsible">
                    
                    <div class="collapsible-header">
                        <b>IndexPut</b> | Input DType:(INT64;INT64;INT64;INT64) | Output DType:(INT64) | Counts:1 | Elapsed Time(us):11999.58
                    </div>
                    <div class="collapsible-content">
                        
                        <div>
                            
                            <p>
                                <b>Suggestion 1:</b> <u>请参考<a href='https://gitee.com/ascend/mstt/blob/master/profiler/msprof_analyze/advisor/doc/Samples%20of%20AI%20CPU%20Operator%20Replacement.md' target='_blank'>链接</a>修改源码，尝试用等价的算子替换indexput算子。</u>
                            </p>
                            
                        </div>
                        
                        <div class="separator"></div>
                        <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(85): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(249): cross_entropy_1d;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(334): dist_cross_entropy;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(360): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): <module></a>
                    </div>
                    
                    <div class="collapsible-header">
                        <b>IndexPut</b> | Input DType:(INT64;INT64;INT64;INT64) | Output DType:(INT64) | Counts:1 | Elapsed Time(us):297.99
                    </div>
                    <div class="collapsible-content">
                        
                        <div>
                            
                            <p>
                                <b>Suggestion 1:</b> <u>请参考<a href='https://gitee.com/ascend/mstt/blob/master/profiler/msprof_analyze/advisor/doc/Samples%20of%20AI%20CPU%20Operator%20Replacement.md' target='_blank'>链接</a>修改源码，尝试用等价的算子替换indexput算子。</u>
                            </p>
                            
                        </div>
                        
                        <div class="separator"></div>
                        <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(89): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(249): cross_entropy_1d;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(334): dist_cross_entropy;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(360): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): <module></a>
                    </div>
                    
                </div>
            </div>
            
        </div>
    </div>
</div>
                
                    
<style>
    .typecol {
        width: 30%;
    }
</style>
<div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #65c294;">AI Core Performance Analysis</h2>
    <div class="collapsible-content">
        
        
        
        
        <a style="font-weight: bold" id="cube_analyze">Cube算子相关分析，参考如下: </a>
        <br>
        <table>
            <tr>
                <th class="typecol">类别</th>
                <th>描述及建议</th>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>性能优化算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> 参考性能优化空间</th></tr>
                    <tr><tr><td>aclnnAddmm_MatMulCommon_MatMulV2</td><td>16384,3584;896,3584;896</td><td>DT_BF16;DT_BF16;FLOAT</td><td>9.55%</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;4736,3584</td><td>DT_BF16;DT_BF16</td><td>9.5%</td></tr><tr><td>aclnnAddmm_MatMulCommon_MatMulV2</td><td>16384,3584;128,3584;128</td><td>DT_BF16;DT_BF16;FLOAT</td><td>4.62%</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;38016,3584</td><td>DT_BF16;DT_BF16</td><td>1.75%</td></tr></tr>
                </table>
                </td>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>不亲和算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> 不亲和类型为</th></tr>
                    <tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;16384,3584</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;4736,3584</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;16384,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,4736;3584,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr><tr><td>aclnnMatmul_MatMulV3Common_MatMulV3</td><td>16384,3584;3584,4736</td><td>DT_BF16;DT_BF16</td><td>内轴无法被256整除</td></tr></tr>
                </table>
                </td>
            </tr>
            
        </table>
        

        
        <a style="font-weight: bold" id="fa_analyze">FA算子相关分析，参考如下: </a>
        <br>
        <table>
            <tr>
                <th class="typecol">类别</th>
                <th>描述及建议</th>
            </tr>
            
            
            
            
            
            
            
            
            
            
            
            
            
            
            <tr>
                <td>bound算子集合</td>
                <td>
                <table>
                <tr><th>name</th><th>shape</th><th>dtype</th><th> bound类型为</th></tr>
                    <tr><tr><td>aclnnFlashAttentionScoreGrad_FlashAttentionScoreGrad_FlashAttentionScoreGrad</td><td>1,7,16384,128;1,7,16384,128;1,7,16384,128;1,7,16384,128;16384,16384;1,7,16384,8;1,7,16384,8;;1,7,16384,128;</td><td>DT_BF16;DT_BF16;DT_BF16;DT_BF16;BOOL;FLOAT;FLOAT;DT_BF16;DT_BF16;INT64</td><td>fixpipe</td></tr><tr><td>aclnnFlashAttentionScore_FlashAttentionScore_FlashAttentionScore</td><td>1,7,16384,128;1,7,16384,128;1,7,16384,128;;;;16384,16384;;;;;</td><td>None</td><td>vec</td></tr></tr>
                </table>
                </td>
            </tr>
            
            
            
            
        </table>
        

        
    </div>
</div>

                
          </div>
      </div>
      
    </div>
</div>

            
          </div>
        </div>
      
        <div class="collapsible">
          <h2 class="collapsible-header">schedule</h2>
          <div class="collapsible-content">
            
            
<div class="collapsible">
    <h2 class="collapsible-header" style="background-color: #fcaf17;">Conjectured GC Analysis</h2>
    <div class="collapsible-content">
      
      <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 6. </a>
      
        <a style="font-weight: bold" id="gc_description">在34079031.859us的空闲时间内几乎没有主机任务，这可能是由Python的异常GC引起的</a>
        <table>
        <tr>
            <th>Suggestions</th>
        </tr>
        
            
            
                <tr>
                    <td>1. 实现高效的Python内存管理；不使用时及时释放内存，避免长期占用；避免对象之间的循环引用。</td>
                </tr>
            
        
            
            
                <tr>
                    <td>2. 使用 gc.set_threshold() 来调整垃圾回收阈值可以延迟垃圾收集，但这是一个临时解决方案。</td>
                </tr>
            
        
            
            
                <tr>
                    <td>3. 使用 gc.disable() 来关闭GC，注意这是个临时解决方案。</td>
                </tr>
            
        
        </table>
        
        <a style="font-weight: bold" id="detail_description">The details of top 2 garbage collection events are as follows:</a>
        <br><br>
            <table>
                <tr>
                
                    <th> timestamp </th>
                
                    <th> duration(us) </th>
                
                </tr>

                
                <tr>
                    
                    <td>1747647483551821.8</td>
                    
                    <td>33818722.418</td>
                    
                </tr>
                
                <tr>
                    
                    <td>1747647606194246.2</td>
                    
                    <td>260309.441</td>
                    
                </tr>
                
            </table>
        
    </div>
</div>
            
            
<div class="collapsible">
  <h2 class="collapsible-header" style="background-color: #65c294;">Affinity API Issues</h2>
  <div class="collapsible-content">
      
      <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 6. </a>
      
      <a style="font-weight: bold" id="timeline_api_instruction">The analysis results of following affinity APIs are based on runtime env
          <span style="font-weight:bold;">cann-8.0.0</span>
          and
          <span style="font-weight:bold;">pytorch-pytorch</span>
      </a>
      <div class="collapsible">

        

      

        

        <div class="collapsible-header">torch_npu.npu_rms_norm</div>
        <div class="collapsible-content">
          <div>
            <a style="font-weight: bold" id="timeline_api_instruction">Suggestion: </a>
            <a>Detailed information of affinity apis please refer to</a>
            <a href="https://gitee.com/ascend/mstt/blob/master/profiler/msprof_analyze/advisor/doc/Samples%20of%20Fused%20Operator%20API%20Replacement.md#torch_npu.npu_rms_norm" target="_blank">API instructions</a>
          </div>
          <div class="collapsible">
          
              <div class="collapsible-header">No.1 code stack, called 28 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(79): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(620): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.2 code stack, called 28 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(79): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(637): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.3 code stack, called 8 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3341): all_gather;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(223): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(638): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.4 code stack, called 4 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3341): all_gather;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(516): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.5 code stack, called 4 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3341): all_gather;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(518): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.6 code stack, called 3 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3341): all_gather;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(517): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.7 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3757): reduce_scatter;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(751): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(223): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(638): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.8 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/_ops.py(1116): __call__;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(582): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.9 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(80): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(620): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.10 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(158): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py(116): decorate_context;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(540): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.11 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3757): reduce_scatter;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(751): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(618): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.12 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(79): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(250): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.13 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3757): reduce_scatter;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(598): backward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(307): apply</a>
              </div>
          
              <div class="collapsible-header">No.14 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py(272): collate_tensor_fn;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py(155): collate;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py(172): <dictcomp>;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py(171): collate;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py(398): default_collate;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py(55): fetch;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py(757): _next_data;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py(701): __next__;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch_npu/profiler/_add_mstx_patch.py(28): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(74): load_batch;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(373): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.15 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(517): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.16 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(207): apply_rotary_pos_emb;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(541): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.17 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(739): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(618): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.18 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(80): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(637): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.19 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(748): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(223): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(638): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.20 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(166): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py(116): decorate_context;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(540): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.21 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3762): reduce_scatter;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(751): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(618): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.22 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1218): <listcomp>;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1218): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(517): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.23 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(235): repeat_kv;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(573): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.24 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(564): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(517): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.25 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(180): rotate_half;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(207): apply_rotary_pos_emb;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(541): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.26 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(748): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(618): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.27 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(172): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py(116): decorate_context;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(540): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.28 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(566): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(223): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(638): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.29 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(739): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(223): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(638): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.30 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(236): repeat_kv;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(574): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.31 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(223): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(638): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.32 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(223): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(638): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.33 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(526): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.34 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(179): rotate_half;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(207): apply_rotary_pos_emb;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(541): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.35 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3341): all_gather;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1073): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1359): gather_forward_split_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1390): gather_sp_output;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(253): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.36 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(84): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(249): cross_entropy_1d;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/loss.py(334): dist_cross_entropy;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(360): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
          </div>
        </div>
        

      

        

        <div class="collapsible-header">torch_npu.npu_confusion_transpose</div>
        <div class="collapsible-content">
          <div>
            <a style="font-weight: bold" id="timeline_api_instruction">Suggestion: </a>
            <a>Detailed information of affinity apis please refer to</a>
            <a href="https://gitee.com/ascend/mstt/blob/master/profiler/msprof_analyze/advisor/doc/Samples%20of%20Fused%20Operator%20API%20Replacement.md#torch_npu.npu_confusion_transpose" target="_blank">API instructions</a>
          </div>
          <div class="collapsible">
          
              <div class="collapsible-header">No.1 code stack, called 32 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3757): reduce_scatter;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(598): backward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(307): apply</a>
              </div>
          
              <div class="collapsible-header">No.2 code stack, called 9 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3341): all_gather;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(766): backward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(307): apply</a>
              </div>
          
              <div class="collapsible-header">No.3 code stack, called 7 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(636): backward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(307): apply</a>
              </div>
          
              <div class="collapsible-header">No.4 code stack, called 6 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3341): all_gather;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(223): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(638): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.5 code stack, called 5 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3341): all_gather;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(516): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.6 code stack, called 5 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(595): backward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(307): apply</a>
              </div>
          
              <div class="collapsible-header">No.7 code stack, called 4 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(585): backward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(307): apply</a>
              </div>
          
              <div class="collapsible-header">No.8 code stack, called 4 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(590): backward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(307): apply</a>
              </div>
          
              <div class="collapsible-header">No.9 code stack, called 3 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3341): all_gather;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(518): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.10 code stack, called 3 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3341): all_gather;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(517): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.11 code stack, called 3 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(580): backward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(307): apply</a>
              </div>
          
              <div class="collapsible-header">No.12 code stack, called 3 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(589): backward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(307): apply</a>
              </div>
          
              <div class="collapsible-header">No.13 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(235): repeat_kv;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(574): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.14 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1218): <listcomp>;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1218): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(518): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.15 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(748): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(618): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.16 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3757): reduce_scatter;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(751): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(223): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(638): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.17 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(80): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(637): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.18 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(597): backward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(307): apply</a>
              </div>
          
              <div class="collapsible-header">No.19 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(638): backward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(307): apply</a>
              </div>
          
              <div class="collapsible-header">No.20 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(528): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.21 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(157): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py(116): decorate_context;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(540): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.22 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(79): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(637): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.23 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1218): <listcomp>;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1218): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(516): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.24 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(163): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py(116): decorate_context;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(540): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.25 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(205): apply_rotary_pos_emb;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(541): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.26 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(206): apply_rotary_pos_emb;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(541): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.27 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(566): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(223): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(638): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.28 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/functional.py(2380): silu;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/activation.py(432): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(223): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(638): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.29 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(179): rotate_half;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(207): apply_rotary_pos_emb;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(541): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.30 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/_ops.py(1116): __call__;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(582): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.31 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(739): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(223): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(638): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.32 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(518): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.33 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3757): reduce_scatter;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(751): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(618): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.34 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(79): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(620): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
          </div>
        </div>
        

      

        

        <div class="collapsible-header">torch_npu.npu_rotary_mul</div>
        <div class="collapsible-content">
          <div>
            <a style="font-weight: bold" id="timeline_api_instruction">Suggestion: </a>
            <a>Detailed information of affinity apis please refer to</a>
            <a href="https://gitee.com/ascend/mstt/blob/master/profiler/msprof_analyze/advisor/doc/Samples%20of%20Fused%20Operator%20API%20Replacement.md#torch_npu.npu_rotary_mul" target="_blank">API instructions</a>
          </div>
          <div class="collapsible">
          
              <div class="collapsible-header">No.1 code stack, called 28 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(179): rotate_half;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(206): apply_rotary_pos_emb;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(541): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.2 code stack, called 28 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(179): rotate_half;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(207): apply_rotary_pos_emb;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(541): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.3 code stack, called 10 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3341): all_gather;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(223): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(638): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.4 code stack, called 5 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3341): all_gather;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(516): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.5 code stack, called 4 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3341): all_gather;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(518): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.6 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(166): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py(116): decorate_context;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(540): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.7 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(235): repeat_kv;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(573): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.8 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3757): reduce_scatter;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(751): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(223): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(638): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.9 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(80): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(637): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.10 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(157): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py(116): decorate_context;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(540): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.11 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3341): all_gather;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(517): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.12 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/_ops.py(1116): __call__;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(582): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.13 code stack, called 2 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3341): all_gather;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(766): backward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(307): apply</a>
              </div>
          
              <div class="collapsible-header">No.14 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1218): <listcomp>;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1218): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(516): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.15 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(163): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py(116): decorate_context;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(540): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.16 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(564): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(516): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.17 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1218): <listcomp>;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1218): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(517): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.18 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1222): _gather;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(561): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(517): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.19 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(564): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1323): linear_gather_forward_reducescatter_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(345): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(517): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.20 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(739): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(618): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.21 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(748): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(618): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.22 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(170): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py(116): decorate_context;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(540): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.23 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(206): apply_rotary_pos_emb;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(541): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.24 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(178): rotate_half;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(207): apply_rotary_pos_emb;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(541): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.25 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(739): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(223): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(638): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.26 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(748): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(223): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(638): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.27 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py(3757): reduce_scatter;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/distributed/c10d_logger.py(83): wrapper;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(751): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(618): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.28 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(575): apply;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(1339): linear_reducescatter_forward_gather_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/linear.py(578): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(618): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(623): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(233): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.29 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(80): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(250): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.30 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/usr/local/python3.10/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py(81): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(250): qwen2_model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/shardformer/modeling/qwen2.py(334): qwen2_for_causal_lm_forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/interface/model.py(30): forward;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(221): forward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1747): _call_impl;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/nn/modules/module.py(1736): _wrapped_call_impl;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/_utils.py(126): model_forward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(270): forward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(406): run_forward_backward;<br/>/home/duanjunwen/ColossalAI/colossalai/pipeline/schedule/one_f_one_b.py(472): forward_backward_step;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/plugin/hybrid_parallel_plugin.py(1409): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/colossalai/booster/booster.py(221): execute_pipeline;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(134): test_hybrid_qwen;<br/>/home/duanjunwen/ColossalAI/applications/ColossalChat/tests/test_hybrid.py(181): &lt;module></a>
              </div>
          
              <div class="collapsible-header">No.31 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(774): backward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(307): apply</a>
              </div>
          
              <div class="collapsible-header">No.32 code stack, called 1 times</div>
              <div class="collapsible-content">
                <a id="timeline_api_stack">/home/duanjunwen/ColossalAI/colossalai/shardformer/layer/_operation.py(811): backward;<br/>/usr/local/python3.10/lib/python3.10/site-packages/torch/autograd/function.py(307): apply</a>
              </div>
          
          </div>
        </div>
        

      

      </div>

  </div>
</div>

            
            
            
          </div>
        </div>
      
        <div class="collapsible">
          <h2 class="collapsible-header">dataloader</h2>
          <div class="collapsible-content">
            
            <div class="collapsible">
  <h2 class="collapsible-header" style="background-color: #B5495B;">Slow Dataloader Issues</h2>
  <div class="collapsible-content">
  
  <a style="font-weight: bold" id="timeline_api_instruction">Analysis of rank 6. </a>
  
    <a style="font-weight: bold" id="timeline_api_instruction">dataloader加载数据速度较慢，一次迭代花费138000.9us，通常小于10000us。</a>
    <table>
        <tr>
            <th>Suggestions</th>
        </tr>

        
            <tr>
                <td>1. 请检查数据目录的磁盘I/O。如果您正在ModelArts中训练模型，请将数据移动到“/cache”或装载更高效的云磁盘以获得更好的I/O。</td>
            </tr>
        
            <tr>
                <td>2. 尝试调整dataloader参数'num_workers'。</td>
            </tr>
        
    </table>

  </div>
</div>
            
          </div>
        </div>
      
      </div>
    </div>

    

<div class="footer">
    <p>Generated by Ascend Training Tools</p>
</div>
    </div>

<script>
    const collapsibleHeaders = document.getElementsByClassName('collapsible-header');

    for (let i = 0; i < collapsibleHeaders.length; i++) {
        collapsibleHeaders[i].addEventListener('click', function (event) {
            const content = this.nextElementSibling;

            // 判断是否展开当前子列表
            const isExpanded = content.style.display === 'block';

            // 获取同级别的子列表标题元素
            const siblingHeaders = this.parentNode.parentNode.getElementsByClassName('collapsible-header');

            // 折叠所有同级别的子列表
            for (let j = 0; j < siblingHeaders.length; j++) {
                const siblingContent = siblingHeaders[j].nextElementSibling;
                if (siblingContent !== content) {
                    siblingContent.style.display = 'none';
                    siblingHeaders[j].classList.remove('active');
                    siblingHeaders[j].classList.remove('opened');
                } else {
                    siblingHeaders[j].classList.add('opened');
                }
            }

            // 切换当前子列表的展开状态
            this.classList.toggle('active');
            if (isExpanded) {
                content.style.display = 'none';
            } else {
                content.style.display = 'block';
            }
        });
    }
</script>

</body>
</html>